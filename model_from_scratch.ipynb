{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b9zbC6ABPBS"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece] seqeval[gpu]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jnGRzmhqBWF1"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast, BertForTokenClassification, BertForSequenceClassification\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import TextDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9ZtmdcxBYMs"
      },
      "outputs": [],
      "source": [
        "!pip install python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vxqkLzucfiG_"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "# Read the JSON file\n",
        "path = \"/content/drive/MyDrive/model/B_data.json\"\n",
        "with open(path, 'r') as f:\n",
        "    dataset = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/model/training_set.json\"\n",
        "with open(path, 'r') as f:\n",
        "    test_dataset = json.load(f)"
      ],
      "metadata": {
        "id": "_ZTqlfb_qrBo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JQin9IoNfnh-"
      },
      "outputs": [],
      "source": [
        "text, intent, ner = [], [], []\n",
        "for i in dataset:\n",
        "    text.append(i['text'])\n",
        "    intent.append(i['intent'])\n",
        "    ner.append(i['entities'].split())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text, test_intent, test_ner = [], [], []\n",
        "for i in test_dataset:\n",
        "    test_text.append(i['text'])\n",
        "    test_intent.append(i['intent'])\n",
        "    test_ner.append(i['entities'].split())"
      ],
      "metadata": {
        "id": "j8zDpSSQq1KY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw-u5fu62PwD",
        "outputId": "6f3e628b-44e0-4da8-ff86-d5ec91ad3f6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'O', 'O', 'O', 'B-DUR', 'I-DUR']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "o = ner[0]\n",
        "o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLPHaXjv1-NC",
        "outputId": "6edc0906-2798-4664-e139-ac8b13694f70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Set', 'a', 'timer', 'for', '10', 'minutes.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "o = text[0].strip().split()\n",
        "o"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just test"
      ],
      "metadata": {
        "id": "LU2rkg73rrvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ner[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3RdWsCKtzx9",
        "outputId": "d4b1bdb8-d92f-4676-c39b-af5603eb2069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-TASK',\n",
              " 'I-TASK',\n",
              " 'B-DATE',\n",
              " 'I-DATE',\n",
              " 'O',\n",
              " 'B-TIME',\n",
              " 'I-TIME']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_ = set(test_intent)\n",
        "num_i = len(unique_)\n",
        "\n",
        "unique_, num_i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8YtM-6frklA",
        "outputId": "c4ba7d85-3f78-4700-ba99-5d3e4f6fb542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({\"'Schedule Appointment'\",\n",
              "  \"'Schedule Meeting'\",\n",
              "  \"'Set Alarm'\",\n",
              "  \"'Set Reminder'\",\n",
              "  \"'Set Timer'\"},\n",
              " 5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_r = [tag for subset in test_ner for tag in subset]\n",
        "uni = set(one_r)\n",
        "num_ = len(uni)\n",
        "uni, num_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ4AXcsfrvsm",
        "outputId": "88a2397b-8ee2-4ecc-84b4-d30087a8d92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'B-DATE',\n",
              "  'B-DUR',\n",
              "  'B-TASK',\n",
              "  'B-TIME',\n",
              "  'I-DATE',\n",
              "  'I-DUR',\n",
              "  'I-TASK',\n",
              "  'I-TIME',\n",
              "  'O'},\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete what is above"
      ],
      "metadata": {
        "id": "TbImDj_wr6iN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTUJWv92f3sx",
        "outputId": "641cbfa4-36d0-4e96-f347-fa4e2ca64eee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({\"'Schedule Appointment'\",\n",
              "  \"'Schedule Meeting'\",\n",
              "  \"'Set Alarm'\",\n",
              "  \"'Set Reminder'\",\n",
              "  \"'Set Timer'\"},\n",
              " 5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "unique_intents = set(intent)\n",
        "num_intent_labels = len(unique_intents)\n",
        "\n",
        "unique_intents, num_intent_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdoGreyqgosK",
        "outputId": "a5564e3c-8ed4-4418-9a12-2e739c07c72c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'B-DATE',\n",
              "  'B-DUR',\n",
              "  'B-TASK',\n",
              "  'B-TIME',\n",
              "  'I-DATE',\n",
              "  'I-DUR',\n",
              "  'I-TASK',\n",
              "  'I-TIME',\n",
              "  'O'},\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "one_dimensional_ner = [tag for subset in ner for tag in subset ]\n",
        "unique_ner = set(one_dimensional_ner)\n",
        "num_ner_labels = len(unique_ner)\n",
        "unique_ner, num_ner_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDSp3FM-gtCb"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "ner_model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=num_ner_labels)\n",
        "intent_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_intent_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gIzCQacBpFzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faeab42a-edcf-4f8b-f6a0-438a0f8b2ff5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'O',\n",
              " 1: 'B-DATE',\n",
              " 2: 'I-DATE',\n",
              " 3: 'B-TIME',\n",
              " 4: 'I-TIME',\n",
              " 5: 'B-TASK',\n",
              " 6: 'I-TASK',\n",
              " 7: 'B-DUR',\n",
              " 8: 'I-DUR'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "labels_to_ids_ner = {\n",
        "    'O': 0,\n",
        "    'B-DATE': 1,\n",
        "    'I-DATE': 2,\n",
        "    'B-TIME': 3,\n",
        "    'I-TIME': 4,\n",
        "    'B-TASK': 5,\n",
        "    'I-TASK': 6,\n",
        "    'B-DUR': 7,\n",
        "    'I-DUR': 8\n",
        "    }\n",
        "\n",
        "ids_to_labels_ner = {v: k for k, v in labels_to_ids_ner.items()}\n",
        "ids_to_labels_ner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "t3y8NTdexh0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ba36e5-1514-41fa-ee28-4dc26b3947f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: \"'Schedule Appointment'\",\n",
              " 1: \"'Schedule Meeting'\",\n",
              " 2: \"'Set Alarm'\",\n",
              " 3: \"'Set Reminder'\",\n",
              " 4: \"'Set Timer'\"}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "labels_to_ids_intent = {\n",
        "    \"'Schedule Appointment'\": 0,\n",
        "    \"'Schedule Meeting'\": 1,\n",
        "    \"'Set Alarm'\": 2,\n",
        "    \"'Set Reminder'\": 3,\n",
        "    \"'Set Timer'\": 4\n",
        "}\n",
        "\n",
        "ids_to_labels_intent = {v: k for k, v in labels_to_ids_intent.items()}\n",
        "ids_to_labels_intent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QvkVdQRVjuLM"
      },
      "outputs": [],
      "source": [
        "class dataset(Dataset):\n",
        "    def __init__(self, text, intent, ner, tokenizer, max_len=128):\n",
        "        self.len = len(text)\n",
        "        self.text = text\n",
        "        self.intent = intent\n",
        "        self.ner = ner\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: get the sentence, ner label, and intent_label\n",
        "        sentence = self.text[index].strip()\n",
        "        intent_label = self.intent[index].strip()\n",
        "        ner_labels = self.ner[index]\n",
        "\n",
        "        # step 2: use tokenizer to encode a sentence (includes padding/truncation up to max length)\n",
        "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" which highlights where each token starts and ends\n",
        "        encoding = self.tokenizer(\n",
        "            sentence,\n",
        "            return_offsets_mapping=True,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_len\n",
        "        )\n",
        "\n",
        "        # step 3: create ner token labels only for first word pieces of each tokenized word\n",
        "        tokenized_ner_labels = [labels_to_ids_ner[label] for label in ner_labels]\n",
        "        # create an empty array of -100 of length max_length\n",
        "        encoded_ner_labels = np.ones(len(encoding['offset_mapping']), dtype=int) * -100\n",
        "\n",
        "        # set only labels whose first offset position is 0 and the second is not 0\n",
        "        i = 0\n",
        "        prev = -1\n",
        "        for idx, mapping in enumerate(encoding['offset_mapping']):\n",
        "            if mapping[0] == mapping[1] == 0:\n",
        "                continue\n",
        "            if mapping[0] != prev:\n",
        "                # overwrite label\n",
        "                encoded_ner_labels[idx] = tokenized_ner_labels[i]\n",
        "                prev = mapping[1]\n",
        "                i += 1\n",
        "            else:\n",
        "                prev = mapping[1]\n",
        "\n",
        "        # create intent token labels\n",
        "        tokenized_intent_label = labels_to_ids_intent[intent_label]\n",
        "\n",
        "        # step 4: turn everything into Pytorch tensors\n",
        "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
        "        item['ner_labels'] = torch.as_tensor(encoded_ner_labels)\n",
        "        item['intent_labels'] = torch.as_tensor(tokenized_intent_label)\n",
        "\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cEaNyuELzNWa"
      },
      "outputs": [],
      "source": [
        "training_set = dataset(text, intent, ner, tokenizer)\n",
        "test_set = dataset(test_text, test_intent, test_ner, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gqvwYgr0jfS"
      },
      "outputs": [],
      "source": [
        "training_set[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbBNIl17mTVH"
      },
      "source": [
        "Let us verify that the input ids and corresponding targets are correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Tf1jeZb0k-U"
      },
      "outputs": [],
      "source": [
        "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[20]['input_ids']), training_set[20]['ner_labels']):\n",
        "    print(f\"{token} -- {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd80tO8InMUM"
      },
      "source": [
        "# I HAVE TO GET RID OF \" IN MY DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k8gK0rcxnQgi"
      },
      "outputs": [],
      "source": [
        "# The dataset is small, batch_size of 1 would not impact the training time significantly\n",
        "training_loader = DataLoader(training_set, batch_size=1)\n",
        "test_loader = DataLoader(test_set, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tjIswaA6ojMQ"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xy1OOPFKZ4fs",
        "outputId": "807f33f5-8d3b-4465-d863-28e84033923b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_model.to(device)\n",
        "intent_model.to(device)"
      ],
      "metadata": {
        "id": "i_S3mmSta5T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf352WfopY0y"
      },
      "source": [
        "The initial loss of the model should be close to -ln(1/num_labels)=-ln(1/9). In this case it is 2.20.\n",
        "Why? Because we are using cross entropy loss. The cross entropy loss is defined as -ln(probability score of the model for the correct class). In the beginning, the weights are random, so the probability distribution for all of the classes for a given token will be uniform, meaning that the probability for the correct class will be near 1/9. The loss for a given token will thus be -ln(1/9). As PyTorch's CrossEntropyLoss (which is used by BertForTokenClassification) uses mean reduction by default, it will compute the mean loss for each of the tokens in the sequence for which a label is provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jjk1I1coLLI",
        "outputId": "fcf78e33-50a3-4ca6-f30d-5d393c38a7f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2205, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "inputs = training_set[2]\n",
        "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
        "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
        "labels = inputs[\"ner_labels\"].unsqueeze(0)\n",
        "\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "outputs = ner_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iJ_clHk6ldm"
      },
      "source": [
        "The shape of logits must be __[batch_size, sequence_length, num_labels]__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "619BrUfmqBKS",
        "outputId": "d5cf254d-bed2-4d60-a30d-164d7f4b5f55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "tr_logits = outputs[1]\n",
        "tr_logits.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDZfSrT-7RdO"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam([\n",
        "    {'params': ner_model.parameters()},\n",
        "    {'params': intent_model.parameters()}\n",
        "], lr=1e-5)"
      ],
      "metadata": {
        "id": "0Jfa3o8tUfLU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Task Learning Architecture"
      ],
      "metadata": {
        "id": "olgG_5XNtDga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Soft Parameter Sharing"
      ],
      "metadata": {
        "id": "Es-sp93awEU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftParameterSharing(torch.nn.Module):\n",
        "    def __init__(self, ner_model, intent_model, alpha):\n",
        "        super(SoftParameterSharing, self).__init__()\n",
        "        self.ner_model = ner_model\n",
        "        self.intent_model = intent_model\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, input_ids, mask, ner_labels, intent_labels):\n",
        "        ner_logits = self.ner_model(input_ids=input_ids, attention_mask=mask, labels=ner_labels)\n",
        "\n",
        "        intent_logits = self.intent_model(input_ids=input_ids, attention_mask=mask, labels=intent_labels)\n",
        "\n",
        "        return ner_logits, intent_logits\n",
        "\n",
        "    def soft_penalty(self):\n",
        "        a = 0\n",
        "        penalty = 0.0\n",
        "        for param_ner, param_intent in zip(self.ner_model.parameters(), self.intent_model.parameters()):\n",
        "            if param_ner.shape != param_intent.shape:\n",
        "            # Resize or repeat elements to match param_intent's shape\n",
        "                if param_ner.shape[0] != param_intent.shape[0]:\n",
        "                    # Calculate the number of times to repeat along the first axis\n",
        "                    repeat_times = param_intent.shape[0] // param_ner.shape[0]\n",
        "                    remaining_items = param_intent.shape[0] % param_ner.shape[0]\n",
        "\n",
        "                    # Expand dimensions of param_ner for element-wise comparison\n",
        "                    expanded_ner = param_ner.unsqueeze(0)\n",
        "\n",
        "                    # Repeat elements along the expanded axis to match the target size\n",
        "                    repeated_ner = expanded_ner.repeat(repeat_times, 1, 1)\n",
        "\n",
        "                    # Concatenate remaining elements, if needed\n",
        "                    if remaining_items > 0:\n",
        "                        remaining_items = expanded_ner.size(1) - repeated_ner.size(1)\n",
        "                        repeated_ner = torch.cat([repeated_ner, expanded_ner[:, :remaining_items]], dim=0)\n",
        "\n",
        "                    # Squeeze the repeated tensor to match original dimensions\n",
        "                    param_ner = repeated_ner.squeeze(0)\n",
        "            a += 1\n",
        "            print(f\"{a}: ner {param_ner.shape}\")\n",
        "            print(f\"{a}: intent {param_intent.shape}\")\n",
        "\n",
        "            penalty += torch.norm(param_ner - param_intent, p=2) ** 2\n",
        "\n",
        "        return self.alpha * penalty\n"
      ],
      "metadata": {
        "id": "CMOzHXE4tHzb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SoftParameterSharing(ner_model, intent_model, 0.1)"
      ],
      "metadata": {
        "id": "KmJTNuQQDTrS"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_ner_loss, tr_ner_accuracy = 0, 0\n",
        "tr_intent_loss, tr_intent_accuracy = 0, 0\n",
        "nb_tr_steps = 0\n",
        "tr_ner_preds, tr_ner_labels = [], []\n",
        "tr_intent_labels, tr_intent_predictions = [], []\n",
        "model.train()\n",
        "\n",
        "\n",
        "for idx, batch in enumerate(training_loader):\n",
        "    ids = batch['input_ids'].to(device, dtype=torch.long)\n",
        "    mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
        "    ner_labels = batch['ner_labels'].to(device, dtype=torch.long)\n",
        "    intent_labels = batch['intent_labels'].to(device, dtype=torch.long)\n",
        "\n",
        "    ner_logits, intent_logits = model(ids, mask, ner_labels, intent_labels)\n",
        "\n",
        "    ner_loss = ner_logits.loss\n",
        "    intent_loss = intent_logits.loss\n",
        "\n",
        "    soft_penalty = model.soft_penalty()\n",
        "\n",
        "    comb_loss = ner_loss + intent_loss + soft_penalty\n",
        "    # till here\n",
        "\n",
        "    tr_ner_loss += ner_logits['loss']\n",
        "    tr_intent_loss += intent_logits['loss']\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "    if idx % 5 == 0:\n",
        "        loss_ner_step = tr_ner_loss / nb_tr_steps\n",
        "        loss_intent_step = tr_intent_loss / nb_tr_steps\n",
        "        print(f\"Training NER loss per {idx} training steps: {loss_ner_step}\")\n",
        "        print(f\"Training INTENT loss per {idx} training steps: {loss_intent_step}\")\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    comb_loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SXHUdjkdDHHv",
        "outputId": "baf9f9f0-2e57-4856-f0f7-d38b00cba145"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: ner torch.Size([30522, 768])\n",
            "1: intent torch.Size([30522, 768])\n",
            "2: ner torch.Size([512, 768])\n",
            "2: intent torch.Size([512, 768])\n",
            "3: ner torch.Size([2, 768])\n",
            "3: intent torch.Size([2, 768])\n",
            "4: ner torch.Size([768])\n",
            "4: intent torch.Size([768])\n",
            "5: ner torch.Size([768])\n",
            "5: intent torch.Size([768])\n",
            "6: ner torch.Size([768, 768])\n",
            "6: intent torch.Size([768, 768])\n",
            "7: ner torch.Size([768])\n",
            "7: intent torch.Size([768])\n",
            "8: ner torch.Size([768, 768])\n",
            "8: intent torch.Size([768, 768])\n",
            "9: ner torch.Size([768])\n",
            "9: intent torch.Size([768])\n",
            "10: ner torch.Size([768, 768])\n",
            "10: intent torch.Size([768, 768])\n",
            "11: ner torch.Size([768])\n",
            "11: intent torch.Size([768])\n",
            "12: ner torch.Size([768, 768])\n",
            "12: intent torch.Size([768, 768])\n",
            "13: ner torch.Size([768])\n",
            "13: intent torch.Size([768])\n",
            "14: ner torch.Size([768])\n",
            "14: intent torch.Size([768])\n",
            "15: ner torch.Size([768])\n",
            "15: intent torch.Size([768])\n",
            "16: ner torch.Size([3072, 768])\n",
            "16: intent torch.Size([3072, 768])\n",
            "17: ner torch.Size([3072])\n",
            "17: intent torch.Size([3072])\n",
            "18: ner torch.Size([768, 3072])\n",
            "18: intent torch.Size([768, 3072])\n",
            "19: ner torch.Size([768])\n",
            "19: intent torch.Size([768])\n",
            "20: ner torch.Size([768])\n",
            "20: intent torch.Size([768])\n",
            "21: ner torch.Size([768])\n",
            "21: intent torch.Size([768])\n",
            "22: ner torch.Size([768, 768])\n",
            "22: intent torch.Size([768, 768])\n",
            "23: ner torch.Size([768])\n",
            "23: intent torch.Size([768])\n",
            "24: ner torch.Size([768, 768])\n",
            "24: intent torch.Size([768, 768])\n",
            "25: ner torch.Size([768])\n",
            "25: intent torch.Size([768])\n",
            "26: ner torch.Size([768, 768])\n",
            "26: intent torch.Size([768, 768])\n",
            "27: ner torch.Size([768])\n",
            "27: intent torch.Size([768])\n",
            "28: ner torch.Size([768, 768])\n",
            "28: intent torch.Size([768, 768])\n",
            "29: ner torch.Size([768])\n",
            "29: intent torch.Size([768])\n",
            "30: ner torch.Size([768])\n",
            "30: intent torch.Size([768])\n",
            "31: ner torch.Size([768])\n",
            "31: intent torch.Size([768])\n",
            "32: ner torch.Size([3072, 768])\n",
            "32: intent torch.Size([3072, 768])\n",
            "33: ner torch.Size([3072])\n",
            "33: intent torch.Size([3072])\n",
            "34: ner torch.Size([768, 3072])\n",
            "34: intent torch.Size([768, 3072])\n",
            "35: ner torch.Size([768])\n",
            "35: intent torch.Size([768])\n",
            "36: ner torch.Size([768])\n",
            "36: intent torch.Size([768])\n",
            "37: ner torch.Size([768])\n",
            "37: intent torch.Size([768])\n",
            "38: ner torch.Size([768, 768])\n",
            "38: intent torch.Size([768, 768])\n",
            "39: ner torch.Size([768])\n",
            "39: intent torch.Size([768])\n",
            "40: ner torch.Size([768, 768])\n",
            "40: intent torch.Size([768, 768])\n",
            "41: ner torch.Size([768])\n",
            "41: intent torch.Size([768])\n",
            "42: ner torch.Size([768, 768])\n",
            "42: intent torch.Size([768, 768])\n",
            "43: ner torch.Size([768])\n",
            "43: intent torch.Size([768])\n",
            "44: ner torch.Size([768, 768])\n",
            "44: intent torch.Size([768, 768])\n",
            "45: ner torch.Size([768])\n",
            "45: intent torch.Size([768])\n",
            "46: ner torch.Size([768])\n",
            "46: intent torch.Size([768])\n",
            "47: ner torch.Size([768])\n",
            "47: intent torch.Size([768])\n",
            "48: ner torch.Size([3072, 768])\n",
            "48: intent torch.Size([3072, 768])\n",
            "49: ner torch.Size([3072])\n",
            "49: intent torch.Size([3072])\n",
            "50: ner torch.Size([768, 3072])\n",
            "50: intent torch.Size([768, 3072])\n",
            "51: ner torch.Size([768])\n",
            "51: intent torch.Size([768])\n",
            "52: ner torch.Size([768])\n",
            "52: intent torch.Size([768])\n",
            "53: ner torch.Size([768])\n",
            "53: intent torch.Size([768])\n",
            "54: ner torch.Size([768, 768])\n",
            "54: intent torch.Size([768, 768])\n",
            "55: ner torch.Size([768])\n",
            "55: intent torch.Size([768])\n",
            "56: ner torch.Size([768, 768])\n",
            "56: intent torch.Size([768, 768])\n",
            "57: ner torch.Size([768])\n",
            "57: intent torch.Size([768])\n",
            "58: ner torch.Size([768, 768])\n",
            "58: intent torch.Size([768, 768])\n",
            "59: ner torch.Size([768])\n",
            "59: intent torch.Size([768])\n",
            "60: ner torch.Size([768, 768])\n",
            "60: intent torch.Size([768, 768])\n",
            "61: ner torch.Size([768])\n",
            "61: intent torch.Size([768])\n",
            "62: ner torch.Size([768])\n",
            "62: intent torch.Size([768])\n",
            "63: ner torch.Size([768])\n",
            "63: intent torch.Size([768])\n",
            "64: ner torch.Size([3072, 768])\n",
            "64: intent torch.Size([3072, 768])\n",
            "65: ner torch.Size([3072])\n",
            "65: intent torch.Size([3072])\n",
            "66: ner torch.Size([768, 3072])\n",
            "66: intent torch.Size([768, 3072])\n",
            "67: ner torch.Size([768])\n",
            "67: intent torch.Size([768])\n",
            "68: ner torch.Size([768])\n",
            "68: intent torch.Size([768])\n",
            "69: ner torch.Size([768])\n",
            "69: intent torch.Size([768])\n",
            "70: ner torch.Size([768, 768])\n",
            "70: intent torch.Size([768, 768])\n",
            "71: ner torch.Size([768])\n",
            "71: intent torch.Size([768])\n",
            "72: ner torch.Size([768, 768])\n",
            "72: intent torch.Size([768, 768])\n",
            "73: ner torch.Size([768])\n",
            "73: intent torch.Size([768])\n",
            "74: ner torch.Size([768, 768])\n",
            "74: intent torch.Size([768, 768])\n",
            "75: ner torch.Size([768])\n",
            "75: intent torch.Size([768])\n",
            "76: ner torch.Size([768, 768])\n",
            "76: intent torch.Size([768, 768])\n",
            "77: ner torch.Size([768])\n",
            "77: intent torch.Size([768])\n",
            "78: ner torch.Size([768])\n",
            "78: intent torch.Size([768])\n",
            "79: ner torch.Size([768])\n",
            "79: intent torch.Size([768])\n",
            "80: ner torch.Size([3072, 768])\n",
            "80: intent torch.Size([3072, 768])\n",
            "81: ner torch.Size([3072])\n",
            "81: intent torch.Size([3072])\n",
            "82: ner torch.Size([768, 3072])\n",
            "82: intent torch.Size([768, 3072])\n",
            "83: ner torch.Size([768])\n",
            "83: intent torch.Size([768])\n",
            "84: ner torch.Size([768])\n",
            "84: intent torch.Size([768])\n",
            "85: ner torch.Size([768])\n",
            "85: intent torch.Size([768])\n",
            "86: ner torch.Size([768, 768])\n",
            "86: intent torch.Size([768, 768])\n",
            "87: ner torch.Size([768])\n",
            "87: intent torch.Size([768])\n",
            "88: ner torch.Size([768, 768])\n",
            "88: intent torch.Size([768, 768])\n",
            "89: ner torch.Size([768])\n",
            "89: intent torch.Size([768])\n",
            "90: ner torch.Size([768, 768])\n",
            "90: intent torch.Size([768, 768])\n",
            "91: ner torch.Size([768])\n",
            "91: intent torch.Size([768])\n",
            "92: ner torch.Size([768, 768])\n",
            "92: intent torch.Size([768, 768])\n",
            "93: ner torch.Size([768])\n",
            "93: intent torch.Size([768])\n",
            "94: ner torch.Size([768])\n",
            "94: intent torch.Size([768])\n",
            "95: ner torch.Size([768])\n",
            "95: intent torch.Size([768])\n",
            "96: ner torch.Size([3072, 768])\n",
            "96: intent torch.Size([3072, 768])\n",
            "97: ner torch.Size([3072])\n",
            "97: intent torch.Size([3072])\n",
            "98: ner torch.Size([768, 3072])\n",
            "98: intent torch.Size([768, 3072])\n",
            "99: ner torch.Size([768])\n",
            "99: intent torch.Size([768])\n",
            "100: ner torch.Size([768])\n",
            "100: intent torch.Size([768])\n",
            "101: ner torch.Size([768])\n",
            "101: intent torch.Size([768])\n",
            "102: ner torch.Size([768, 768])\n",
            "102: intent torch.Size([768, 768])\n",
            "103: ner torch.Size([768])\n",
            "103: intent torch.Size([768])\n",
            "104: ner torch.Size([768, 768])\n",
            "104: intent torch.Size([768, 768])\n",
            "105: ner torch.Size([768])\n",
            "105: intent torch.Size([768])\n",
            "106: ner torch.Size([768, 768])\n",
            "106: intent torch.Size([768, 768])\n",
            "107: ner torch.Size([768])\n",
            "107: intent torch.Size([768])\n",
            "108: ner torch.Size([768, 768])\n",
            "108: intent torch.Size([768, 768])\n",
            "109: ner torch.Size([768])\n",
            "109: intent torch.Size([768])\n",
            "110: ner torch.Size([768])\n",
            "110: intent torch.Size([768])\n",
            "111: ner torch.Size([768])\n",
            "111: intent torch.Size([768])\n",
            "112: ner torch.Size([3072, 768])\n",
            "112: intent torch.Size([3072, 768])\n",
            "113: ner torch.Size([3072])\n",
            "113: intent torch.Size([3072])\n",
            "114: ner torch.Size([768, 3072])\n",
            "114: intent torch.Size([768, 3072])\n",
            "115: ner torch.Size([768])\n",
            "115: intent torch.Size([768])\n",
            "116: ner torch.Size([768])\n",
            "116: intent torch.Size([768])\n",
            "117: ner torch.Size([768])\n",
            "117: intent torch.Size([768])\n",
            "118: ner torch.Size([768, 768])\n",
            "118: intent torch.Size([768, 768])\n",
            "119: ner torch.Size([768])\n",
            "119: intent torch.Size([768])\n",
            "120: ner torch.Size([768, 768])\n",
            "120: intent torch.Size([768, 768])\n",
            "121: ner torch.Size([768])\n",
            "121: intent torch.Size([768])\n",
            "122: ner torch.Size([768, 768])\n",
            "122: intent torch.Size([768, 768])\n",
            "123: ner torch.Size([768])\n",
            "123: intent torch.Size([768])\n",
            "124: ner torch.Size([768, 768])\n",
            "124: intent torch.Size([768, 768])\n",
            "125: ner torch.Size([768])\n",
            "125: intent torch.Size([768])\n",
            "126: ner torch.Size([768])\n",
            "126: intent torch.Size([768])\n",
            "127: ner torch.Size([768])\n",
            "127: intent torch.Size([768])\n",
            "128: ner torch.Size([3072, 768])\n",
            "128: intent torch.Size([3072, 768])\n",
            "129: ner torch.Size([3072])\n",
            "129: intent torch.Size([3072])\n",
            "130: ner torch.Size([768, 3072])\n",
            "130: intent torch.Size([768, 3072])\n",
            "131: ner torch.Size([768])\n",
            "131: intent torch.Size([768])\n",
            "132: ner torch.Size([768])\n",
            "132: intent torch.Size([768])\n",
            "133: ner torch.Size([768])\n",
            "133: intent torch.Size([768])\n",
            "134: ner torch.Size([768, 768])\n",
            "134: intent torch.Size([768, 768])\n",
            "135: ner torch.Size([768])\n",
            "135: intent torch.Size([768])\n",
            "136: ner torch.Size([768, 768])\n",
            "136: intent torch.Size([768, 768])\n",
            "137: ner torch.Size([768])\n",
            "137: intent torch.Size([768])\n",
            "138: ner torch.Size([768, 768])\n",
            "138: intent torch.Size([768, 768])\n",
            "139: ner torch.Size([768])\n",
            "139: intent torch.Size([768])\n",
            "140: ner torch.Size([768, 768])\n",
            "140: intent torch.Size([768, 768])\n",
            "141: ner torch.Size([768])\n",
            "141: intent torch.Size([768])\n",
            "142: ner torch.Size([768])\n",
            "142: intent torch.Size([768])\n",
            "143: ner torch.Size([768])\n",
            "143: intent torch.Size([768])\n",
            "144: ner torch.Size([3072, 768])\n",
            "144: intent torch.Size([3072, 768])\n",
            "145: ner torch.Size([3072])\n",
            "145: intent torch.Size([3072])\n",
            "146: ner torch.Size([768, 3072])\n",
            "146: intent torch.Size([768, 3072])\n",
            "147: ner torch.Size([768])\n",
            "147: intent torch.Size([768])\n",
            "148: ner torch.Size([768])\n",
            "148: intent torch.Size([768])\n",
            "149: ner torch.Size([768])\n",
            "149: intent torch.Size([768])\n",
            "150: ner torch.Size([768, 768])\n",
            "150: intent torch.Size([768, 768])\n",
            "151: ner torch.Size([768])\n",
            "151: intent torch.Size([768])\n",
            "152: ner torch.Size([768, 768])\n",
            "152: intent torch.Size([768, 768])\n",
            "153: ner torch.Size([768])\n",
            "153: intent torch.Size([768])\n",
            "154: ner torch.Size([768, 768])\n",
            "154: intent torch.Size([768, 768])\n",
            "155: ner torch.Size([768])\n",
            "155: intent torch.Size([768])\n",
            "156: ner torch.Size([768, 768])\n",
            "156: intent torch.Size([768, 768])\n",
            "157: ner torch.Size([768])\n",
            "157: intent torch.Size([768])\n",
            "158: ner torch.Size([768])\n",
            "158: intent torch.Size([768])\n",
            "159: ner torch.Size([768])\n",
            "159: intent torch.Size([768])\n",
            "160: ner torch.Size([3072, 768])\n",
            "160: intent torch.Size([3072, 768])\n",
            "161: ner torch.Size([3072])\n",
            "161: intent torch.Size([3072])\n",
            "162: ner torch.Size([768, 3072])\n",
            "162: intent torch.Size([768, 3072])\n",
            "163: ner torch.Size([768])\n",
            "163: intent torch.Size([768])\n",
            "164: ner torch.Size([768])\n",
            "164: intent torch.Size([768])\n",
            "165: ner torch.Size([768])\n",
            "165: intent torch.Size([768])\n",
            "166: ner torch.Size([768, 768])\n",
            "166: intent torch.Size([768, 768])\n",
            "167: ner torch.Size([768])\n",
            "167: intent torch.Size([768])\n",
            "168: ner torch.Size([768, 768])\n",
            "168: intent torch.Size([768, 768])\n",
            "169: ner torch.Size([768])\n",
            "169: intent torch.Size([768])\n",
            "170: ner torch.Size([768, 768])\n",
            "170: intent torch.Size([768, 768])\n",
            "171: ner torch.Size([768])\n",
            "171: intent torch.Size([768])\n",
            "172: ner torch.Size([768, 768])\n",
            "172: intent torch.Size([768, 768])\n",
            "173: ner torch.Size([768])\n",
            "173: intent torch.Size([768])\n",
            "174: ner torch.Size([768])\n",
            "174: intent torch.Size([768])\n",
            "175: ner torch.Size([768])\n",
            "175: intent torch.Size([768])\n",
            "176: ner torch.Size([3072, 768])\n",
            "176: intent torch.Size([3072, 768])\n",
            "177: ner torch.Size([3072])\n",
            "177: intent torch.Size([3072])\n",
            "178: ner torch.Size([768, 3072])\n",
            "178: intent torch.Size([768, 3072])\n",
            "179: ner torch.Size([768])\n",
            "179: intent torch.Size([768])\n",
            "180: ner torch.Size([768])\n",
            "180: intent torch.Size([768])\n",
            "181: ner torch.Size([768])\n",
            "181: intent torch.Size([768])\n",
            "182: ner torch.Size([768, 768])\n",
            "182: intent torch.Size([768, 768])\n",
            "183: ner torch.Size([768])\n",
            "183: intent torch.Size([768])\n",
            "184: ner torch.Size([768, 768])\n",
            "184: intent torch.Size([768, 768])\n",
            "185: ner torch.Size([768])\n",
            "185: intent torch.Size([768])\n",
            "186: ner torch.Size([768, 768])\n",
            "186: intent torch.Size([768, 768])\n",
            "187: ner torch.Size([768])\n",
            "187: intent torch.Size([768])\n",
            "188: ner torch.Size([768, 768])\n",
            "188: intent torch.Size([768, 768])\n",
            "189: ner torch.Size([768])\n",
            "189: intent torch.Size([768])\n",
            "190: ner torch.Size([768])\n",
            "190: intent torch.Size([768])\n",
            "191: ner torch.Size([768])\n",
            "191: intent torch.Size([768])\n",
            "192: ner torch.Size([3072, 768])\n",
            "192: intent torch.Size([3072, 768])\n",
            "193: ner torch.Size([3072])\n",
            "193: intent torch.Size([3072])\n",
            "194: ner torch.Size([768, 3072])\n",
            "194: intent torch.Size([768, 3072])\n",
            "195: ner torch.Size([768])\n",
            "195: intent torch.Size([768])\n",
            "196: ner torch.Size([768])\n",
            "196: intent torch.Size([768])\n",
            "197: ner torch.Size([768])\n",
            "197: intent torch.Size([768])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e2358c1c9b8d>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mintent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintent_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0msoft_penalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoft_penalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcomb_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mner_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mintent_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msoft_penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-b737bfd9c085>\u001b[0m in \u001b[0;36msoft_penalty\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining_items\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0mremaining_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpanded_ner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrepeated_ner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                         \u001b[0mrepeated_ner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrepeated_ner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_ner\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mremaining_items\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0;31m# Squeeze the repeated tensor to match original dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 9 but got size 0 for tensor number 1 in the list."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TxB_EoOXvWm"
      },
      "source": [
        "# Just testing the models; delete it after finished"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kISPCk3X1VU"
      },
      "source": [
        "____"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_PxBooK8cdo"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    tr_ner_loss, tr_ner_accuracy = 0, 0\n",
        "    tr_intent_loss, tr_intent_accuracy = 0, 0\n",
        "    nb_tr_steps = 0\n",
        "    tr_ner_preds, tr_ner_labels = [], []\n",
        "    tr_intent_labels, tr_intent_predictions = [], []\n",
        "    ner_model.train()\n",
        "    intent_model.train()\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "        ids = batch['input_ids'].to(device, dtype=torch.long)\n",
        "        mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
        "        ner_labels = batch['ner_labels'].to(device, dtype=torch.long)\n",
        "        intent_labels = batch['intent_labels'].to(device, dtype=torch.long)\n",
        "\n",
        "        ner_logits = ner_model(input_ids=ids, attention_mask=mask, labels=ner_labels)\n",
        "\n",
        "        # here we train an intent_model\n",
        "        intent_logits = intent_model(input_ids=ids, attention_mask=mask, labels=intent_labels)\n",
        "\n",
        "        ner_loss = ner_logits.loss\n",
        "        intent_loss = intent_logits.loss\n",
        "\n",
        "        comb_loss = ner_loss + intent_loss\n",
        "        # till here\n",
        "\n",
        "        tr_ner_loss += ner_logits['loss']\n",
        "        tr_intent_loss += intent_logits['loss']\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "        if idx % 5 == 0:\n",
        "            loss_ner_step = tr_ner_loss / nb_tr_steps\n",
        "            loss_intent_step = tr_intent_loss / nb_tr_steps\n",
        "            print(f\"Training NER loss per {idx} training steps: {loss_ner_step}\")\n",
        "            print(f\"Training INTENT loss per {idx} training steps: {loss_intent_step}\")\n",
        "\n",
        "        # compute training accuracy (FOR NER)\n",
        "        flattened_ner_targets = ner_labels.view(-1) # shape (batch_size * seq_len)\n",
        "        active_ner_logits = ner_logits.logits.view(-1, ner_model.num_labels) # shape (batch_size*seq_len, num_labels)\n",
        "        flattened_ner_predictions = torch.argmax(active_ner_logits, axis=1) # shape (batch_size * seq_len)\n",
        "\n",
        "        # compute accuracy only at active labels\n",
        "        active_ner_accuracy = ner_labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
        "        ac_ner_labels = torch.masked_select(flattened_ner_targets, active_ner_accuracy)\n",
        "        ner_predictions = torch.masked_select(flattened_ner_predictions, active_ner_accuracy)\n",
        "\n",
        "        tr_ner_labels.extend(ac_ner_labels)\n",
        "        tr_ner_preds.extend(ner_predictions)\n",
        "\n",
        "        # compute accuracy for intent_model\n",
        "        # I CAN MAKE THE CALCULATION MUCH EASIER\n",
        "        # FIGURE IT OUT\n",
        "        flattened_intent_targets = intent_labels.view(-1)\n",
        "        active_intent_logits = intent_logits.logits.view(-1, intent_model.num_labels)\n",
        "        flattened_intent_predictions = torch.argmax(active_intent_logits, axis=1)\n",
        "\n",
        "        sample_intent_accuracy = intent_labels.view(-1)\n",
        "        active_intent_accuracy = torch.ones_like(sample_intent_accuracy, dtype=torch.bool)\n",
        "\n",
        "        ac_intent_labels = torch.masked_select(flattened_intent_targets, active_intent_accuracy)\n",
        "        intent_predictions = torch.masked_select(flattened_intent_predictions, active_intent_accuracy)\n",
        "\n",
        "        tr_intent_labels.extend(ac_intent_labels)\n",
        "        tr_intent_predictions.extend(intent_predictions)\n",
        "\n",
        "        tmp_tr_ner_accuracy = accuracy_score(ac_ner_labels.cpu().numpy(), ner_predictions.cpu().numpy())\n",
        "        tmp_tr_intent_accuracy = accuracy_score(ac_intent_labels.cpu().numpy(), intent_predictions.cpu().numpy())\n",
        "\n",
        "\n",
        "        tr_ner_accuracy += tmp_tr_ner_accuracy\n",
        "        tr_intent_accuracy += tmp_tr_intent_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=ner_model.parameters(), max_norm=10\n",
        "        )\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=intent_model.parameters(), max_norm=10\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        comb_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = (tr_ner_loss + tr_intent_loss) / nb_tr_steps\n",
        "    tr_ner_accuracy = tr_ner_accuracy / nb_tr_steps\n",
        "    tr_intent_accuracy = tr_intent_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training NER accuracy epoch: {tr_ner_accuracy}\")\n",
        "    print(f\"Training INTENT accuracy epoch: {tr_intent_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):\n",
        "    print(f\"Training epoch: {epoch+1}\")\n",
        "    print(\"----------------------------\")\n",
        "    train(epoch)"
      ],
      "metadata": {
        "id": "JHz3SgpIfsxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce6e2de-e52a-48ca-a8c0-44b281c03269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "----------------------------\n",
            "Training NER loss per 0 training steps: 2.292585611343384\n",
            "Training INTENT loss per 0 training steps: 1.070138692855835\n",
            "Training NER loss per 5 training steps: 2.065725088119507\n",
            "Training INTENT loss per 5 training steps: 1.6158603429794312\n",
            "Training NER loss per 10 training steps: 1.9141026735305786\n",
            "Training INTENT loss per 10 training steps: 1.5342868566513062\n",
            "Training NER loss per 15 training steps: 1.7891895771026611\n",
            "Training INTENT loss per 15 training steps: 1.4432443380355835\n",
            "Training NER loss per 20 training steps: 1.7322863340377808\n",
            "Training INTENT loss per 20 training steps: 1.4711107015609741\n",
            "Training NER loss per 25 training steps: 1.6883087158203125\n",
            "Training INTENT loss per 25 training steps: 1.4129210710525513\n",
            "Training NER loss per 30 training steps: 1.639518141746521\n",
            "Training INTENT loss per 30 training steps: 1.4211585521697998\n",
            "Training loss epoch: 2.9790008068084717\n",
            "Training NER accuracy epoch: 0.48376409304980733\n",
            "Training INTENT accuracy epoch: 0.5428571428571428\n",
            "Training epoch: 2\n",
            "----------------------------\n",
            "Training NER loss per 0 training steps: 0.9474005699157715\n",
            "Training INTENT loss per 0 training steps: 0.8799883127212524\n",
            "Training NER loss per 5 training steps: 0.8535735011100769\n",
            "Training INTENT loss per 5 training steps: 1.1996008157730103\n",
            "Training NER loss per 10 training steps: 0.9435178637504578\n",
            "Training INTENT loss per 10 training steps: 1.247714877128601\n",
            "Training NER loss per 15 training steps: 0.9619663953781128\n",
            "Training INTENT loss per 15 training steps: 1.1523497104644775\n",
            "Training NER loss per 20 training steps: 0.9854699969291687\n",
            "Training INTENT loss per 20 training steps: 1.1808489561080933\n",
            "Training NER loss per 25 training steps: 0.9940418601036072\n",
            "Training INTENT loss per 25 training steps: 1.1076956987380981\n",
            "Training NER loss per 30 training steps: 0.9902365207672119\n",
            "Training INTENT loss per 30 training steps: 1.0880364179611206\n",
            "Training loss epoch: 2.0538039207458496\n",
            "Training NER accuracy epoch: 0.6978630100058673\n",
            "Training INTENT accuracy epoch: 0.6571428571428571\n",
            "Training epoch: 3\n",
            "----------------------------\n",
            "Training NER loss per 0 training steps: 0.5673689842224121\n",
            "Training INTENT loss per 0 training steps: 0.5063186883926392\n",
            "Training NER loss per 5 training steps: 0.47645530104637146\n",
            "Training INTENT loss per 5 training steps: 1.1676913499832153\n",
            "Training NER loss per 10 training steps: 0.585486114025116\n",
            "Training INTENT loss per 10 training steps: 1.0922305583953857\n",
            "Training NER loss per 15 training steps: 0.5995115041732788\n",
            "Training INTENT loss per 15 training steps: 0.9763868451118469\n",
            "Training NER loss per 20 training steps: 0.6488369703292847\n",
            "Training INTENT loss per 20 training steps: 0.9352244138717651\n",
            "Training NER loss per 25 training steps: 0.6698668599128723\n",
            "Training INTENT loss per 25 training steps: 0.8740770816802979\n",
            "Training NER loss per 30 training steps: 0.6716185808181763\n",
            "Training INTENT loss per 30 training steps: 0.8363621234893799\n",
            "Training loss epoch: 1.492553472518921\n",
            "Training NER accuracy epoch: 0.8364398300112588\n",
            "Training INTENT accuracy epoch: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the model"
      ],
      "metadata": {
        "id": "GIBPDraRgRps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(ner_model, intent_model, test_loader):\n",
        "    ner_model.eval()\n",
        "    intent_model.eval()\n",
        "\n",
        "    eval_ner_loss, eval_ner_accuracy = 0, 0\n",
        "    eval_intent_loss, eval_intent_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_ner_preds, eval_ner_labels = [], []\n",
        "    eval_intent_preds, eval_intent_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(test_loader):\n",
        "            ids = batch['input_ids'].to(device, dtype=torch.long)\n",
        "            mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
        "            ner_labels = batch['ner_labels'].to(device, dtype=torch.long)\n",
        "            intent_labels = batch['intent_labels'].to(device, dtype=torch.long)\n",
        "\n",
        "            ner_logits = ner_model(input_ids=ids, attention_mask=mask, labels=ner_labels)\n",
        "            intent_logits = intent_model(input_ids=ids, attention_mask=mask, labels=intent_labels)\n",
        "\n",
        "            eval_ner_loss += ner_logits['loss']\n",
        "            eval_intent_loss += intent_logits['loss']\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "            if idx % 5 == 0:\n",
        "                loss_ner_step = eval_ner_loss / nb_eval_steps\n",
        "                loss_intent_step = eval_intent_loss / nb_eval_steps\n",
        "                print(f\"Validation NER loss per {idx} training steps: {loss_ner_step}\")\n",
        "                print(f\"Validation INTENT loss per {idx} training steps: {loss_intent_step}\")\n",
        "\n",
        "            # compute training accuracy (FOR NER)\n",
        "            flattened_ner_targets = ner_labels.view(-1) # shape (batch_size * seq_len)\n",
        "            active_ner_logits = ner_logits.logits.view(-1, ner_model.num_labels) # shape (batch_size*seq_len, num_labels)\n",
        "            flattened_ner_predictions = torch.argmax(active_ner_logits, axis=1) # shape (batch_size * seq_len)\n",
        "\n",
        "            # compute accuracy only at active labels\n",
        "            active_ner_accuracy = ner_labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
        "            ac_ner_labels = torch.masked_select(flattened_ner_targets, active_ner_accuracy)\n",
        "            ner_predictions = torch.masked_select(flattened_ner_predictions, active_ner_accuracy)\n",
        "\n",
        "            eval_ner_labels.extend(ac_ner_labels)\n",
        "            eval_ner_preds.extend(ner_predictions)\n",
        "\n",
        "            # compute accuracy for intent_model\n",
        "            # I CAN MAKE THE CALCULATION MUCH EASIER\n",
        "            # FIGURE IT OUT\n",
        "            flattened_intent_targets = intent_labels.view(-1)\n",
        "            active_intent_logits = intent_logits.logits.view(-1, intent_model.num_labels)\n",
        "            flattened_intent_predictions = torch.argmax(active_intent_logits, axis=1)\n",
        "\n",
        "            sample_intent_accuracy = intent_labels.view(-1)\n",
        "            active_intent_accuracy = torch.ones_like(sample_intent_accuracy, dtype=torch.bool)\n",
        "\n",
        "            ac_intent_labels = torch.masked_select(flattened_intent_targets, active_intent_accuracy)\n",
        "            intent_predictions = torch.masked_select(flattened_intent_predictions, active_intent_accuracy)\n",
        "\n",
        "            eval_intent_labels.extend(ac_intent_labels)\n",
        "            eval_intent_preds.extend(intent_predictions)\n",
        "\n",
        "            tmp_eval_ner_accuracy = accuracy_score(ac_ner_labels.cpu().numpy(), ner_predictions.cpu().numpy())\n",
        "            tmp_eval_intent_accuracy = accuracy_score(ac_intent_labels.cpu().numpy(), intent_predictions.cpu().numpy())\n",
        "\n",
        "            eval_ner_accuracy += tmp_eval_ner_accuracy\n",
        "            eval_intent_accuracy += tmp_eval_intent_accuracy\n",
        "\n",
        "    v_ner_labels = [ids_to_labels_ner[id.item()] for id in eval_ner_labels]\n",
        "    v_ner_predictions = [ids_to_labels_ner[id.item()] for id in eval_ner_preds]\n",
        "\n",
        "    v_intent_labels = [ids_to_labels_intent[id.item()] for id in eval_intent_labels]\n",
        "    v_intent_predictions = [ids_to_labels_intent[id.item()] for id in eval_intent_preds]\n",
        "\n",
        "    v_ner_loss = eval_ner_loss / nb_eval_steps\n",
        "    v_intent_loss = eval_intent_loss / nb_eval_steps\n",
        "    eval_ner_accuracy = eval_ner_accuracy / nb_eval_steps\n",
        "    eval_intent_accuracy = eval_intent_accuracy / nb_eval_steps\n",
        "    print(f\"Validation NER loss: {v_ner_loss}\")\n",
        "    print(f\"Validation INTENT loss: {v_intent_loss}\")\n",
        "    print(f\"Validation NER accuracy: {eval_ner_accuracy}\")\n",
        "    print(f\"Validation INTENT accuracy: {eval_intent_accuracy}\")\n",
        "\n",
        "    return v_ner_labels, v_ner_predictions, v_intent_labels, v_intent_predictions"
      ],
      "metadata": {
        "id": "sSumzyRcf4bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_ner_labels, v_ner_predictions, v_intent_labels, v_intent_predictions = eval(ner_model, intent_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD4nCQVzpPep",
        "outputId": "eef95b81-6410-4bbf-fe9c-a4beb8e9c447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation NER loss per 0 training steps: 0.4739464521408081\n",
            "Validation INTENT loss per 0 training steps: 1.371886134147644\n",
            "Validation NER loss per 5 training steps: 0.7722306847572327\n",
            "Validation INTENT loss per 5 training steps: 0.9412998557090759\n",
            "Validation NER loss per 10 training steps: 0.7568662762641907\n",
            "Validation INTENT loss per 10 training steps: 0.9561601281166077\n",
            "Validation NER loss per 15 training steps: 0.7189643383026123\n",
            "Validation INTENT loss per 15 training steps: 0.810491681098938\n",
            "Validation NER loss per 20 training steps: 0.6933809518814087\n",
            "Validation INTENT loss per 20 training steps: 0.760198712348938\n",
            "Validation NER loss: 0.7181467413902283\n",
            "Validation INTENT loss: 0.7319214940071106\n",
            "Validation NER accuracy: 0.8080488955488957\n",
            "Validation INTENT accuracy: 0.9166666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report(v_ner_labels, v_ner_predictions))"
      ],
      "metadata": {
        "id": "Fv6qk2pYppKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Mr_kyDspvN0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}