{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8Yda_U1XKPS",
        "outputId": "b0f374d0-3068-4a01-ab66-d3b9abb42929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.3)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.2.0)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.15.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.41)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.40.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.3.0.post0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.9.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.20.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb pytorch-lightning transformers[sentencepiece] onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from transformers import BertModel, BertConfig\n",
        "from torchmetrics import Metric\n",
        "import os\n",
        "import onnx\n",
        "import onnx.numpy_helper as numpy_helper\n",
        "import json\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Ke2MfmPrbPCP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init()\n",
        "artifact = run.use_artifact('prince_/lit-wandb/model.ckpt:v34', type='model')\n",
        "artifact_dir = artifact.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "Wxlo7Ub-ZrR4",
        "outputId": "40a36f1e-d5d2-41a5-c8ed-eb3ff705c63e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprince_\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240210_110005-86jalsr8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/prince_/uncategorized/runs/86jalsr8' target=\"_blank\">alight-lantern-8</a></strong> to <a href='https://wandb.ai/prince_/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/prince_/uncategorized' target=\"_blank\">https://wandb.ai/prince_/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/prince_/uncategorized/runs/86jalsr8' target=\"_blank\">https://wandb.ai/prince_/uncategorized/runs/86jalsr8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model.ckpt:v34, 417.81MB. 1 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 0:0:3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.use_artifact??"
      ],
      "metadata": {
        "id": "iMs2yA6UqxFy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the documentation on hot to save the model in torch"
      ],
      "metadata": {
        "id": "UX-tS1UUrT3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pl.LightningModule.to_torchscript??"
      ],
      "metadata": {
        "id": "MjKhhlB_bQuI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/model/B_data.json\"\n",
        "with open(path, 'r') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "path = \"/content/drive/MyDrive/model/training_set.json\"\n",
        "with open(path, 'r') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "text, intent, ner = [], [], []\n",
        "for i in dataset:\n",
        "    text.append(i['text'])\n",
        "    intent.append(i['intent'])\n",
        "    ner.append(i['entities'].split())\n",
        "\n",
        "test_text, test_intent, test_ner = [], [], []\n",
        "for i in test_dataset:\n",
        "    test_text.append(i['text'])\n",
        "    test_intent.append(i['intent'])\n",
        "    test_ner.append(i['entities'].split())\n",
        "\n",
        "unique_intents = set(intent)\n",
        "num_intent_labels = len(unique_intents)\n",
        "\n",
        "one_dimensional_ner = [tag for subset in ner for tag in subset ]\n",
        "unique_ner = set(one_dimensional_ner)\n",
        "num_ner_labels = len(unique_ner)\n",
        "\n"
      ],
      "metadata": {
        "id": "lkMYyRezWSWs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_ner_labels, num_intent_labels = 9, 5"
      ],
      "metadata": {
        "id": "PV-_K10i6Ksv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyAccuracy(Metric):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.add_state('total', default=torch.tensor(0), dist_reduce_fx='sum')\n",
        "        self.add_state('correct', default=torch.tensor(0), dist_reduce_fx='sum')\n",
        "\n",
        "    def update(self, logits, labels, num_labels):\n",
        "\n",
        "        flattened_targets = labels.view(-1) # shape (batch_size, sequence_len)\n",
        "        active_logits = logits.view(-1, num_labels) # shape (batch_size * sequence_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * sequence_len)\n",
        "\n",
        "        # compute accuracy only at active labels\n",
        "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, sequnce_len)\n",
        "        ac_labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        self.correct += torch.sum(ac_labels == predictions)\n",
        "        self.total += torch.numel(ac_labels)\n",
        "\n",
        "    def compute(self):\n",
        "        return self.correct.float() / self.total.float()"
      ],
      "metadata": {
        "id": "5dVTD3Ae3J1-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskBertModel(pl.LightningModule):\n",
        "\n",
        "    \"\"\"\n",
        "    Multi-task Bert model for Named Entity Recognition (NER) and Intent Classification\n",
        "\n",
        "    Args:\n",
        "        config (BertConfig): Bert model configuration.\n",
        "        num_ner_labels (int): The number of labels for NER task.\n",
        "        num_intent_labels (int): The number of labels for Intent Classification task.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, num_ner_labels, num_intent_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_ner_labels = num_ner_labels\n",
        "        self.num_intent_labels = num_intent_labels\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        self.model = BertModel(config=config)\n",
        "\n",
        "        self.ner_classifier = torch.nn.Linear(config.hidden_size, self.num_ner_labels)\n",
        "        self.intent_classifier = torch.nn.Linear(config.hidden_size, self.num_intent_labels)\n",
        "\n",
        "        # log hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.accuracy = MyAccuracy()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None):\n",
        "\n",
        "        \"\"\"\n",
        "        Perform a forward pass through Multi-task Bert model.\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): Input token IDs.\n",
        "            attention_mask (torch.Tensor): Attention mask for input tokens.\n",
        "            ner_labels (torch.Tensor): Labels for NER task.\n",
        "            intent_labels (torch.Tensor): Labels for Intent Classification task.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor,torch.Tensor,torch.Tensor,torch.Tensor]: NER loss, NER logits, Intent loss, Intent logits.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If ner_labels or intent_labels were not provided.\n",
        "        \"\"\"\n",
        "\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        ner_logits = self.ner_classifier(sequence_output)\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        intent_logits = self.intent_classifier(pooled_output)\n",
        "\n",
        "        return ner_logits, intent_logits\n",
        "\n",
        "    def training_step(self: pl.LightningModule, batch, batch_idx: int):\n",
        "        loss, ner_logits, intent_logits, ner_labels, intent_labels = self._common_step(batch, batch_idx)\n",
        "        accuracy_ner = self.accuracy(ner_logits, ner_labels, num_ner_labels)\n",
        "        accuracy_intent = self.accuracy(intent_logits, intent_labels, num_intent_labels)\n",
        "        self.log_dict({'training_loss': loss, 'ner_accuracy': accuracy_ner, 'intent_accuracy': accuracy_intent},\n",
        "                      on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_start(self):\n",
        "        self.validation_step_outputs_ner = []\n",
        "        self.validation_step_outputs_intent = []\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, ner_logits, intent_logits, ner_labels, intent_labels = self._common_step(batch, batch_idx)\n",
        "        # self.log('val_loss', loss)\n",
        "        accuracy_ner = self.accuracy(ner_logits, ner_labels, num_ner_labels)\n",
        "        accuracy_intent = self.accuracy(intent_logits, intent_labels, num_intent_labels)\n",
        "        self.log_dict({'validation_loss': loss, 'val_ner_accuracy': accuracy_ner, 'val_intent_accuracy': accuracy_intent},\n",
        "                      on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        self.validation_step_outputs_ner.append(ner_logits)\n",
        "        self.validation_step_outputs_intent.append(intent_logits)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        validation_step_outputs_ner = self.validation_step_outputs_ner\n",
        "        validation_step_outputs_intent = self.validation_step_outputs_intent\n",
        "\n",
        "        dummy_input = torch.zeros((1, 128), device=self.device, dtype=torch.long)\n",
        "        model_filename = f\"model_{str(self.global_step).zfill(5)}.onnx\"\n",
        "        torch.onnx.export(self, dummy_input, model_filename)\n",
        "        artifact = wandb.Artifact(name=\"model.ckpt\", type=\"model\")\n",
        "        artifact.add_file(model_filename)\n",
        "        self.logger.experiment.log_artifact(artifact)\n",
        "\n",
        "        flattened_logits_ner = torch.flatten(torch.cat(validation_step_outputs_ner))\n",
        "        flattened_logits_intent = torch.flatten(torch.cat(validation_step_outputs_intent))\n",
        "        self.logger.experiment.log(\n",
        "            {\"valid/ner_logits\": wandb.Histogram(flattened_logits_ner.to('cpu')),\n",
        "             \"valid/intent_logits\": wandb.Histogram(flattened_logits_intent.to('cpu')),\n",
        "             \"global_step\": self.global_step}\n",
        "        )\n",
        "\n",
        "    def _common_step(self, batch, batch_idx):\n",
        "        ids = batch['input_ids']\n",
        "        mask = batch['attention_mask']\n",
        "        ner_labels = batch['ner_labels']\n",
        "        intent_labels = batch['intent_labels']\n",
        "\n",
        "        ner_logits, intent_logits = self.forward(ids, mask)\n",
        "\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        ner_loss = criterion(ner_logits.view(-1, self.num_ner_labels), ner_labels.view(-1))\n",
        "        intent_loss = criterion(intent_logits.view(-1, self.num_intent_labels), intent_labels.view(-1))\n",
        "\n",
        "        loss = ner_loss + intent_loss\n",
        "        return loss, ner_logits, intent_logits, ner_labels, intent_labels\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-5)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "BTtfIyOm0EfW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BertConfig.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "maX6y2v_3rOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c61cdab-b9d5-4c88-cc4b-9d7ba58873d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiTaskBertModel(config, num_ner_labels, num_intent_labels)"
      ],
      "metadata": {
        "id": "6DeHcXps6WS8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = 0\n",
        "for name, param in model.named_parameters():\n",
        "    total_params += param.numel()\n",
        "\n",
        "print(\"Total number of parameters in the model:\", total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLmvVnsx8heS",
        "outputId": "b253206d-b47d-4cf0-e009-b9fe992d3b4c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 109493006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model = onnx.load(os.path.join(artifact_dir, \"model_00280.onnx\"))"
      ],
      "metadata": {
        "id": "aHICmJzYXsID"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = {}\n",
        "\n",
        "for initializer in onnx_model.graph.initializer:\n",
        "    # Convert the initializer's data to a PyTorch tensor\n",
        "    tensor = numpy_helper.to_array(initializer)\n",
        "\n",
        "    # Use the initializer's name as the key in the state_dict\n",
        "    state_dict[initializer.name] = torch.tensor(tensor)"
      ],
      "metadata": {
        "id": "V-YHlTRjEPlk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in state_dict.values())\n",
        "total_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKUvBeom8lQJ",
        "outputId": "625f16c0-f895-4a1b-f7fa-5c2b8ae76d09"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109493006"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict"
      ],
      "metadata": {
        "id": "ZpAjngKLXRIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "gpgyy5Xv_OB0",
        "outputId": "3eac9fab-c8e3-4432-8dfc-115652e1aa0f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for MultiTaskBertModel:\n\tMissing key(s) in state_dict: \"model.encoder.layer.0.attention.self.query.weight\", \"model.encoder.layer.0.attention.self.key.weight\", \"model.encoder.layer.0.attention.self.value.weight\", \"model.encoder.layer.0.attention.output.dense.weight\", \"model.encoder.layer.0.intermediate.dense.weight\", \"model.encoder.layer.0.output.dense.weight\", \"model.encoder.layer.1.attention.self.query.weight\", \"model.encoder.layer.1.attention.self.key.weight\", \"model.encoder.layer.1.attention.self.value.weight\", \"model.encoder.layer.1.attention.output.dense.weight\", \"model.encoder.layer.1.intermediate.dense.weight\", \"model.encoder.layer.1.output.dense.weight\", \"model.encoder.layer.2.attention.self.query.weight\", \"model.encoder.layer.2.attention.self.key.weight\", \"model.encoder.layer.2.attention.self.value.weight\", \"model.encoder.layer.2.attention.output.dense.weight\", \"model.encoder.layer.2.intermediate.dense.weight\", \"model.encoder.layer.2.output.dense.weight\", \"model.encoder.layer.3.attention.self.query.weight\", \"model.encoder.layer.3.attention.self.key.weight\", \"model.encoder.layer.3.attention.self.value.weight\", \"model.encoder.layer.3.attention.output.dense.weight\", \"model.encoder.layer.3.intermediate.dense.weight\", \"model.encoder.layer.3.output.dense.weight\", \"model.encoder.layer.4.attention.self.query.weight\", \"model.encoder.layer.4.attention.self.key.weight\", \"model.encoder.layer.4.attention.self.value.weight\", \"model.encoder.layer.4.attention.output.dense.weight\", \"model.encoder.layer.4.intermediate.dense.weight\", \"model.encoder.layer.4.output.dense.weight\", \"model.encoder.layer.5.attention.self.query.weight\", \"model.encoder.layer.5.attention.self.key.weight\", \"model.encoder.layer.5.attention.self.value.weight\", \"model.encoder.layer.5.attention.output.dense.weight\", \"model.encoder.layer.5.intermediate.dense.weight\", \"model.encoder.layer.5.output.dense.weight\", \"model.encoder.layer.6.attention.self.query.weight\", \"model.encoder.layer.6.attention.self.key.weight\", \"model.encoder.layer.6.attention.self.value.weight\", \"model.encoder.layer.6.attention.output.dense.weight\", \"model.encoder.layer.6.intermediate.dense.weight\", \"model.encoder.layer.6.output.dense.weight\", \"model.encoder.layer.7.attention.self.query.weight\", \"model.encoder.layer.7.attention.self.key.weight\", \"model.encoder.layer.7.attention.self.value.weight\", \"model.encoder.layer.7.attention.output.dense.weight\", \"model.encoder.layer.7.intermediate.dense.weight\", \"model.encoder.layer.7.output.dense.weight\", \"model.encoder.layer.8.attention.self.query.weight\", \"model.encoder.layer.8.attention.self.key.weight\", \"model.encoder.layer.8.attention.self.value.weight\", \"model.encoder.layer.8.attention.output.dense.weight\", \"model.encoder.layer.8.intermediate.dense.weight\", \"model.encoder.layer.8.output.dense.weight\", \"model.encoder.layer.9.attention.self.query.weight\", \"model.encoder.layer.9.attention.self.key.weight\", \"model.encoder.layer.9.attention.self.value.weight\", \"model.encoder.layer.9.attention.output.dense.weight\", \"model.encoder.layer.9.intermediate.dense.weight\", \"model.encoder.layer.9.output.dense.weight\", \"model.encoder.layer.10.attention.self.query.weight\", \"model.encoder.layer.10.attention.self.key.weight\", \"model.encoder.layer.10.attention.self.value.weight\", \"model.encoder.layer.10.attention.output.dense.weight\", \"model.encoder.layer.10.intermediate.dense.weight\", \"model.encoder.layer.10.output.dense.weight\", \"model.encoder.layer.11.attention.self.query.weight\", \"model.encoder.layer.11.attention.self.key.weight\", \"model.encoder.layer.11.attention.self.value.weight\", \"model.encoder.layer.11.attention.output.dense.weight\", \"model.encoder.layer.11.intermediate.dense.weight\", \"model.encoder.layer.11.output.dense.weight\", \"ner_classifier.weight\". \n\tUnexpected key(s) in state_dict: \"onnx::MatMul_1288\", \"onnx::MatMul_1289\", \"onnx::MatMul_1295\", \"onnx::MatMul_1310\", \"onnx::MatMul_1311\", \"onnx::MatMul_1312\", \"onnx::MatMul_1313\", \"onnx::MatMul_1314\", \"onnx::MatMul_1320\", \"onnx::MatMul_1335\", \"onnx::MatMul_1336\", \"onnx::MatMul_1337\", \"onnx::MatMul_1338\", \"onnx::MatMul_1339\", \"onnx::MatMul_1345\", \"onnx::MatMul_1360\", \"onnx::MatMul_1361\", \"onnx::MatMul_1362\", \"onnx::MatMul_1363\", \"onnx::MatMul_1364\", \"onnx::MatMul_1370\", \"onnx::MatMul_1385\", \"onnx::MatMul_1386\", \"onnx::MatMul_1387\", \"onnx::MatMul_1388\", \"onnx::MatMul_1389\", \"onnx::MatMul_1395\", \"onnx::MatMul_1410\", \"onnx::MatMul_1411\", \"onnx::MatMul_1412\", \"onnx::MatMul_1413\", \"onnx::MatMul_1414\", \"onnx::MatMul_1420\", \"onnx::MatMul_1435\", \"onnx::MatMul_1436\", \"onnx::MatMul_1437\", \"onnx::MatMul_1438\", \"onnx::MatMul_1439\", \"onnx::MatMul_1445\", \"onnx::MatMul_1460\", \"onnx::MatMul_1461\", \"onnx::MatMul_1462\", \"onnx::MatMul_1463\", \"onnx::MatMul_1464\", \"onnx::MatMul_1470\", \"onnx::MatMul_1485\", \"onnx::MatMul_1486\", \"onnx::MatMul_1487\", \"onnx::MatMul_1488\", \"onnx::MatMul_1489\", \"onnx::MatMul_1495\", \"onnx::MatMul_1510\", \"onnx::MatMul_1511\", \"onnx::MatMul_1512\", \"onnx::MatMul_1513\", \"onnx::MatMul_1514\", \"onnx::MatMul_1520\", \"onnx::MatMul_1535\", \"onnx::MatMul_1536\", \"onnx::MatMul_1537\", \"onnx::MatMul_1538\", \"onnx::MatMul_1539\", \"onnx::MatMul_1545\", \"onnx::MatMul_1560\", \"onnx::MatMul_1561\", \"onnx::MatMul_1562\", \"onnx::MatMul_1563\", \"onnx::MatMul_1564\", \"onnx::MatMul_1570\", \"onnx::MatMul_1585\", \"onnx::MatMul_1586\", \"onnx::MatMul_1587\", \"onnx::MatMul_1588\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-decb596209c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2153\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MultiTaskBertModel:\n\tMissing key(s) in state_dict: \"model.encoder.layer.0.attention.self.query.weight\", \"model.encoder.layer.0.attention.self.key.weight\", \"model.encoder.layer.0.attention.self.value.weight\", \"model.encoder.layer.0.attention.output.dense.weight\", \"model.encoder.layer.0.intermediate.dense.weight\", \"model.encoder.layer.0.output.dense.weight\", \"model.encoder.layer.1.attention.self.query.weight\", \"model.encoder.layer.1.attention.self.key.weight\", \"model.encoder.layer.1.attention.self.value.weight\", \"model.encoder.layer.1.attention.output.dense.weight\", \"model.encoder.layer.1.intermediate.dense.weight\", \"model.encoder.layer.1.output.dense.weight\", \"model.encoder.layer.2.attention.self.query.weight\", \"model.encoder.layer.2.attention.self.key.weight\", \"model.encoder.layer.2.attention.self.value.weight\", \"model.encoder.layer.2.attention.output.dense.weight\", \"model.encoder.layer.2.intermediate.dense.weight\", \"model.encoder.layer.2.output.dense.weight\", \"model.encoder.layer.3.attention.self.query.weight\", \"model.encoder.layer.3.attention.self.key.weight\", \"model.encoder.layer.3.attention.self.value.weight\", \"model.encoder.layer.3.attention.output.dense.weight\", \"model.encoder.layer.3.intermediate.dense.weight\", \"model.encoder.layer.3.output.dense.weight\", \"model.encoder.layer.4.attention.self.query.weight\", \"model.encoder.layer.4.attention.self.key.weight\", \"model.encoder.layer.4.attention.self.value.weight\", \"model.encoder.layer.4.attention.output.dense.weight\", \"model.encoder.layer.4...\n\tUnexpected key(s) in state_dict: \"onnx::MatMul_1288\", \"onnx::MatMul_1289\", \"onnx::MatMul_1295\", \"onnx::MatMul_1310\", \"onnx::MatMul_1311\", \"onnx::MatMul_1312\", \"onnx::MatMul_1313\", \"onnx::MatMul_1314\", \"onnx::MatMul_1320\", \"onnx::MatMul_1335\", \"onnx::MatMul_1336\", \"onnx::MatMul_1337\", \"onnx::MatMul_1338\", \"onnx::MatMul_1339\", \"onnx::MatMul_1345\", \"onnx::MatMul_1360\", \"onnx::MatMul_1361\", \"onnx::MatMul_1362\", \"onnx::MatMul_1363\", \"onnx::MatMul_1364\", \"onnx::MatMul_1370\", \"onnx::MatMul_1385\", \"onnx::MatMul_1386\", \"onnx::MatMul_1387\", \"onnx::MatMul_1388\", \"onnx::MatMul_1389\", \"onnx::MatMul_1395\", \"onnx::MatMul_1410\", \"onnx::MatMul_1411\", \"onnx::MatMul_1412\", \"onnx::MatMul_1413\", \"onnx::MatMul_1414\", \"onnx::MatMul_1420\", \"onnx::MatMul_1435\", \"onnx::MatMul_1436\", \"onnx::MatMul_1437\", \"onnx::MatMul_1438\", \"onnx::MatMul_1439\", \"onnx::MatMul_1445\", \"onnx::MatMul_1460\", \"onnx::MatMul_1461\", \"onnx::MatMul_1462\", \"onnx::MatMul_1463\", \"onnx::MatMul_1464\", \"onnx::MatMul_1470\", \"onnx::MatMul_1485\", \"onnx::MatMul_1486\", \"onnx::MatMul_1487\", \"onnx::MatMul_1488\", \"onnx::MatMul_1489\", \"onnx::MatMul_1495\", \"onnx::MatMul_1510\", \"onnx::MatMul_1511\", \"onnx::MatMul_1512\", \"onnx::MatMul_1513\", \"onnx::MatMul_1514\", \"onnx::MatMul_1520\", \"onnx::MatMul_1535\", \"onnx::MatMul_1536\", \"onnx::MatMul_1537\", \"onnx::MatMul_1538\", \"onnx::MatMul_1539\", \"onnx::MatMul_1545\", \"onnx::MatMul_1560\", \"onnx::MatMul_1561\", \"onnx::MatMul_1562\", \"onnx::MatMul_1563\", \"onnx::MatMul_1564\", \"onnx::MatMul_1570\", \"onnx::MatMul_..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scripted_model = model.to_torchscript(file_path=artifact_dir)"
      ],
      "metadata": {
        "id": "vqbXQrL660uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Save the TorchScript model to a .pt file\n",
        "torch.jit.save(model, \"model.pt\")\n",
        "\n",
        "# Step 2: Log the .pt file as an artifact\n",
        "run = wandb.init(project=\"prince\", job_type=\"model_upload\")\n",
        "artifact = wandb.Artifact(\"model\", type=\"model\")\n",
        "artifact.add_file(\"model.pt\")\n",
        "run.log_artifact(artifact)\n",
        "\n",
        "# Step 3: Finish the run\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "5C1ZNcvb8A7e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}