{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8Yda_U1XKPS",
        "outputId": "d2acf6b2-2022-493b-ff0a-0d01510e5507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.2.0-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.40.2-py2.py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.7/257.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.3.0.post0-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.9.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, lightning-utilities, docker-pycreds, gitdb, torchmetrics, GitPython, wandb, pytorch-lightning\n",
            "Successfully installed GitPython-3.1.41 docker-pycreds-0.4.0 gitdb-4.0.11 lightning-utilities-0.10.1 pytorch-lightning-2.2.0 sentry-sdk-1.40.2 setproctitle-1.3.3 smmap-5.0.1 torchmetrics-1.3.0.post0 wandb-0.16.3\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb pytorch-lightning transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from transformers import BertModel, BertConfig\n",
        "from torchmetrics import Metric"
      ],
      "metadata": {
        "id": "Ke2MfmPrbPCP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init()\n",
        "artifact = run.use_artifact('prince_/lit-wandb/model.ckpt:v34', type='model')\n",
        "artifact_dir = artifact.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "Wxlo7Ub-ZrR4",
        "outputId": "ef963260-422c-40e8-feea-cf7b98dd423e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240208_155934-skganzhw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/prince_/uncategorized/runs/skganzhw' target=\"_blank\">restful-forest-1</a></strong> to <a href='https://wandb.ai/prince_/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/prince_/uncategorized' target=\"_blank\">https://wandb.ai/prince_/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/prince_/uncategorized/runs/skganzhw' target=\"_blank\">https://wandb.ai/prince_/uncategorized/runs/skganzhw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model.ckpt:v34, 417.81MB. 1 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 0:0:20.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pl.LightningModule.to_torchscript??"
      ],
      "metadata": {
        "id": "MjKhhlB_bQuI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_ner_labels, num_intent_labels = 9, 5"
      ],
      "metadata": {
        "id": "PV-_K10i6Ksv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyAccuracy(Metric):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.add_state('total', default=torch.tensor(0), dist_reduce_fx='sum')\n",
        "        self.add_state('correct', default=torch.tensor(0), dist_reduce_fx='sum')\n",
        "\n",
        "    def update(self, logits, labels, num_labels):\n",
        "\n",
        "        flattened_targets = labels.view(-1) # shape (batch_size, sequence_len)\n",
        "        active_logits = logits.view(-1, num_labels) # shape (batch_size * sequence_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * sequence_len)\n",
        "\n",
        "        # compute accuracy only at active labels\n",
        "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, sequnce_len)\n",
        "        ac_labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        self.correct += torch.sum(ac_labels == predictions)\n",
        "        self.total += torch.numel(ac_labels)\n",
        "\n",
        "    def compute(self):\n",
        "        return self.correct.float() / self.total.float()"
      ],
      "metadata": {
        "id": "5dVTD3Ae3J1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskBertModel(pl.LightningModule):\n",
        "\n",
        "    \"\"\"\n",
        "    Multi-task Bert model for Named Entity Recognition (NER) and Intent Classification\n",
        "\n",
        "    Args:\n",
        "        config (BertConfig): Bert model configuration.\n",
        "        num_ner_labels (int): The number of labels for NER task.\n",
        "        num_intent_labels (int): The number of labels for Intent Classification task.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, num_ner_labels, num_intent_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_ner_labels = num_ner_labels\n",
        "        self.num_intent_labels = num_intent_labels\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        self.model = BertModel(config=config)\n",
        "\n",
        "        self.ner_classifier = torch.nn.Linear(config.hidden_size, self.num_ner_labels)\n",
        "        self.intent_classifier = torch.nn.Linear(config.hidden_size, self.num_intent_labels)\n",
        "\n",
        "        # log hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.accuracy = MyAccuracy()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None):\n",
        "\n",
        "        \"\"\"\n",
        "        Perform a forward pass through Multi-task Bert model.\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): Input token IDs.\n",
        "            attention_mask (torch.Tensor): Attention mask for input tokens.\n",
        "            ner_labels (torch.Tensor): Labels for NER task.\n",
        "            intent_labels (torch.Tensor): Labels for Intent Classification task.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor,torch.Tensor,torch.Tensor,torch.Tensor]: NER loss, NER logits, Intent loss, Intent logits.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If ner_labels or intent_labels were not provided.\n",
        "        \"\"\"\n",
        "\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        ner_logits = self.ner_classifier(sequence_output)\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        intent_logits = self.intent_classifier(pooled_output)\n",
        "\n",
        "        return ner_logits, intent_logits\n",
        "\n",
        "    def training_step(self: pl.LightningModule, batch, batch_idx: int):\n",
        "        loss, ner_logits, intent_logits, ner_labels, intent_labels = self._common_step(batch, batch_idx)\n",
        "        accuracy_ner = self.accuracy(ner_logits, ner_labels, num_ner_labels)\n",
        "        accuracy_intent = self.accuracy(intent_logits, intent_labels, num_intent_labels)\n",
        "        self.log_dict({'training_loss': loss, 'ner_accuracy': accuracy_ner, 'intent_accuracy': accuracy_intent},\n",
        "                      on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_start(self):\n",
        "        self.validation_step_outputs_ner = []\n",
        "        self.validation_step_outputs_intent = []\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, ner_logits, intent_logits, ner_labels, intent_labels = self._common_step(batch, batch_idx)\n",
        "        # self.log('val_loss', loss)\n",
        "        accuracy_ner = self.accuracy(ner_logits, ner_labels, num_ner_labels)\n",
        "        accuracy_intent = self.accuracy(intent_logits, intent_labels, num_intent_labels)\n",
        "        self.log_dict({'validation_loss': loss, 'val_ner_accuracy': accuracy_ner, 'val_intent_accuracy': accuracy_intent},\n",
        "                      on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        self.validation_step_outputs_ner.append(ner_logits)\n",
        "        self.validation_step_outputs_intent.append(intent_logits)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        validation_step_outputs_ner = self.validation_step_outputs_ner\n",
        "        validation_step_outputs_intent = self.validation_step_outputs_intent\n",
        "\n",
        "        dummy_input = torch.zeros((1, 128), device=self.device, dtype=torch.long)\n",
        "        model_filename = f\"model_{str(self.global_step).zfill(5)}.onnx\"\n",
        "        torch.onnx.export(self, dummy_input, model_filename)\n",
        "        artifact = wandb.Artifact(name=\"model.ckpt\", type=\"model\")\n",
        "        artifact.add_file(model_filename)\n",
        "        self.logger.experiment.log_artifact(artifact)\n",
        "\n",
        "        flattened_logits_ner = torch.flatten(torch.cat(validation_step_outputs_ner))\n",
        "        flattened_logits_intent = torch.flatten(torch.cat(validation_step_outputs_intent))\n",
        "        self.logger.experiment.log(\n",
        "            {\"valid/ner_logits\": wandb.Histogram(flattened_logits_ner.to('cpu')),\n",
        "             \"valid/intent_logits\": wandb.Histogram(flattened_logits_intent.to('cpu')),\n",
        "             \"global_step\": self.global_step}\n",
        "        )\n",
        "\n",
        "    def _common_step(self, batch, batch_idx):\n",
        "        ids = batch['input_ids']\n",
        "        mask = batch['attention_mask']\n",
        "        ner_labels = batch['ner_labels']\n",
        "        intent_labels = batch['intent_labels']\n",
        "\n",
        "        ner_logits, intent_logits = self.forward(ids, mask)\n",
        "\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        ner_loss = criterion(ner_logits.view(-1, self.num_ner_labels), ner_labels.view(-1))\n",
        "        intent_loss = criterion(intent_logits.view(-1, self.num_intent_labels), intent_labels.view(-1))\n",
        "\n",
        "        loss = ner_loss + intent_loss\n",
        "        return loss, ner_logits, intent_logits, ner_labels, intent_labels\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-5)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "BTtfIyOm0EfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BertConfig()"
      ],
      "metadata": {
        "id": "maX6y2v_3rOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiTaskBertModel(config, num_ner_labels, num_intent_labels)"
      ],
      "metadata": {
        "id": "6DeHcXps6WS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to_torchscript(file_path=artifact_dir)"
      ],
      "metadata": {
        "id": "vqbXQrL660uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `script_model` is your TorchScript model\n",
        "script_model = torch.jit.script(model)\n",
        "\n",
        "# Step 1: Save the TorchScript model to a .pt file\n",
        "torch.jit.save(script_model, \"model.pt\")\n",
        "\n",
        "# Step 2: Log the .pt file as an artifact\n",
        "run = wandb.init(project=\"your_project_name\", job_type=\"model_upload\")\n",
        "artifact = wandb.Artifact(\"model\", type=\"model\")\n",
        "artifact.add_file(\"model.pt\")\n",
        "run.log_artifact(artifact)\n",
        "\n",
        "# Step 3: Finish the run\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "5C1ZNcvb8A7e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}