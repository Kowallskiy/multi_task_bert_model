{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8Yda_U1XKPS",
        "outputId": "845ff80b-6d75-4ebd-f2a3-d17f00928b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.2.0-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.40.3-py2.py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.8/257.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.3.0.post0-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.9.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.20.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, onnx, lightning-utilities, docker-pycreds, gitdb, torchmetrics, GitPython, wandb, pytorch-lightning\n",
            "Successfully installed GitPython-3.1.41 docker-pycreds-0.4.0 gitdb-4.0.11 lightning-utilities-0.10.1 onnx-1.15.0 pytorch-lightning-2.2.0 sentry-sdk-1.40.3 setproctitle-1.3.3 smmap-5.0.1 torchmetrics-1.3.0.post0 wandb-0.16.3\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb pytorch-lightning transformers[sentencepiece] onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from transformers import BertModel, BertConfig\n",
        "from torchmetrics import Metric\n",
        "import os\n",
        "import onnx\n",
        "import onnx.numpy_helper as numpy_helper\n"
      ],
      "metadata": {
        "id": "Ke2MfmPrbPCP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init()\n",
        "artifact = run.use_artifact('prince_/lit-wandb/model.ckpt:v34', type='model')\n",
        "artifact_dir = artifact.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "Wxlo7Ub-ZrR4",
        "outputId": "bb94f765-ce8c-4723-8aca-502e56ff9645"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240210_092339-fra3acrf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/prince_/uncategorized/runs/fra3acrf' target=\"_blank\">glistening-envelope-5</a></strong> to <a href='https://wandb.ai/prince_/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/prince_/uncategorized' target=\"_blank\">https://wandb.ai/prince_/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/prince_/uncategorized/runs/fra3acrf' target=\"_blank\">https://wandb.ai/prince_/uncategorized/runs/fra3acrf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model.ckpt:v34, 417.81MB. 1 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 0:0:5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the documentation on hot to save the model in torch"
      ],
      "metadata": {
        "id": "UX-tS1UUrT3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pl.LightningModule.to_torchscript??"
      ],
      "metadata": {
        "id": "MjKhhlB_bQuI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_ner_labels, num_intent_labels = 9, 5"
      ],
      "metadata": {
        "id": "PV-_K10i6Ksv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyAccuracy(Metric):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.add_state('total', default=torch.tensor(0), dist_reduce_fx='sum')\n",
        "        self.add_state('correct', default=torch.tensor(0), dist_reduce_fx='sum')\n",
        "\n",
        "    def update(self, logits, labels, num_labels):\n",
        "\n",
        "        flattened_targets = labels.view(-1) # shape (batch_size, sequence_len)\n",
        "        active_logits = logits.view(-1, num_labels) # shape (batch_size * sequence_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * sequence_len)\n",
        "\n",
        "        # compute accuracy only at active labels\n",
        "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, sequnce_len)\n",
        "        ac_labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        self.correct += torch.sum(ac_labels == predictions)\n",
        "        self.total += torch.numel(ac_labels)\n",
        "\n",
        "    def compute(self):\n",
        "        return self.correct.float() / self.total.float()"
      ],
      "metadata": {
        "id": "5dVTD3Ae3J1-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskBertModel(pl.LightningModule):\n",
        "\n",
        "    \"\"\"\n",
        "    Multi-task Bert model for Named Entity Recognition (NER) and Intent Classification\n",
        "\n",
        "    Args:\n",
        "        config (BertConfig): Bert model configuration.\n",
        "        num_ner_labels (int): The number of labels for NER task.\n",
        "        num_intent_labels (int): The number of labels for Intent Classification task.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, num_ner_labels, num_intent_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_ner_labels = num_ner_labels\n",
        "        self.num_intent_labels = num_intent_labels\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        self.model = BertModel(config=config)\n",
        "\n",
        "        self.ner_classifier = torch.nn.Linear(config.hidden_size, self.num_ner_labels)\n",
        "        self.intent_classifier = torch.nn.Linear(config.hidden_size, self.num_intent_labels)\n",
        "\n",
        "        # log hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.accuracy = MyAccuracy()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None):\n",
        "\n",
        "        \"\"\"\n",
        "        Perform a forward pass through Multi-task Bert model.\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): Input token IDs.\n",
        "            attention_mask (torch.Tensor): Attention mask for input tokens.\n",
        "            ner_labels (torch.Tensor): Labels for NER task.\n",
        "            intent_labels (torch.Tensor): Labels for Intent Classification task.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor,torch.Tensor,torch.Tensor,torch.Tensor]: NER loss, NER logits, Intent loss, Intent logits.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If ner_labels or intent_labels were not provided.\n",
        "        \"\"\"\n",
        "\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        ner_logits = self.ner_classifier(sequence_output)\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        intent_logits = self.intent_classifier(pooled_output)\n",
        "\n",
        "        return ner_logits, intent_logits\n",
        "\n",
        "    def training_step(self: pl.LightningModule, batch, batch_idx: int):\n",
        "        loss, ner_logits, intent_logits, ner_labels, intent_labels = self._common_step(batch, batch_idx)\n",
        "        accuracy_ner = self.accuracy(ner_logits, ner_labels, num_ner_labels)\n",
        "        accuracy_intent = self.accuracy(intent_logits, intent_labels, num_intent_labels)\n",
        "        self.log_dict({'training_loss': loss, 'ner_accuracy': accuracy_ner, 'intent_accuracy': accuracy_intent},\n",
        "                      on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_start(self):\n",
        "        self.validation_step_outputs_ner = []\n",
        "        self.validation_step_outputs_intent = []\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, ner_logits, intent_logits, ner_labels, intent_labels = self._common_step(batch, batch_idx)\n",
        "        # self.log('val_loss', loss)\n",
        "        accuracy_ner = self.accuracy(ner_logits, ner_labels, num_ner_labels)\n",
        "        accuracy_intent = self.accuracy(intent_logits, intent_labels, num_intent_labels)\n",
        "        self.log_dict({'validation_loss': loss, 'val_ner_accuracy': accuracy_ner, 'val_intent_accuracy': accuracy_intent},\n",
        "                      on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        self.validation_step_outputs_ner.append(ner_logits)\n",
        "        self.validation_step_outputs_intent.append(intent_logits)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        validation_step_outputs_ner = self.validation_step_outputs_ner\n",
        "        validation_step_outputs_intent = self.validation_step_outputs_intent\n",
        "\n",
        "        dummy_input = torch.zeros((1, 128), device=self.device, dtype=torch.long)\n",
        "        model_filename = f\"model_{str(self.global_step).zfill(5)}.onnx\"\n",
        "        torch.onnx.export(self, dummy_input, model_filename)\n",
        "        artifact = wandb.Artifact(name=\"model.ckpt\", type=\"model\")\n",
        "        artifact.add_file(model_filename)\n",
        "        self.logger.experiment.log_artifact(artifact)\n",
        "\n",
        "        flattened_logits_ner = torch.flatten(torch.cat(validation_step_outputs_ner))\n",
        "        flattened_logits_intent = torch.flatten(torch.cat(validation_step_outputs_intent))\n",
        "        self.logger.experiment.log(\n",
        "            {\"valid/ner_logits\": wandb.Histogram(flattened_logits_ner.to('cpu')),\n",
        "             \"valid/intent_logits\": wandb.Histogram(flattened_logits_intent.to('cpu')),\n",
        "             \"global_step\": self.global_step}\n",
        "        )\n",
        "\n",
        "    def _common_step(self, batch, batch_idx):\n",
        "        ids = batch['input_ids']\n",
        "        mask = batch['attention_mask']\n",
        "        ner_labels = batch['ner_labels']\n",
        "        intent_labels = batch['intent_labels']\n",
        "\n",
        "        ner_logits, intent_logits = self.forward(ids, mask)\n",
        "\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        ner_loss = criterion(ner_logits.view(-1, self.num_ner_labels), ner_labels.view(-1))\n",
        "        intent_loss = criterion(intent_logits.view(-1, self.num_intent_labels), intent_labels.view(-1))\n",
        "\n",
        "        loss = ner_loss + intent_loss\n",
        "        return loss, ner_logits, intent_logits, ner_labels, intent_labels\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-5)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "BTtfIyOm0EfW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BertConfig()"
      ],
      "metadata": {
        "id": "maX6y2v_3rOE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiTaskBertModel(config, num_ner_labels, num_intent_labels)"
      ],
      "metadata": {
        "id": "6DeHcXps6WS8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model = onnx.load(os.path.join(artifact_dir, \"model_00280.onnx\"))\n",
        "\n",
        "state_dict = {}\n",
        "\n",
        "# Iterate over the model's intializers, which contain the weights and biases\n",
        "for initializer in onnx_model.graph.initializer:\n",
        "    # Convert the initializer's data into Pytorch tensor\n",
        "    tensor = numpy_helper.to_array(initializer)\n",
        "\n",
        "    state_dict[initializer.name] = torch.tensor(tensor)"
      ],
      "metadata": {
        "id": "V-YHlTRjEPlk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "gpgyy5Xv_OB0",
        "outputId": "ae76b951-d174-4ca7-9d31-3c22e218e335"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for MultiTaskBertModel:\n\tMissing key(s) in state_dict: \"model.encoder.layer.0.attention.self.query.weight\", \"model.encoder.layer.0.attention.self.key.weight\", \"model.encoder.layer.0.attention.self.value.weight\", \"model.encoder.layer.0.attention.output.dense.weight\", \"model.encoder.layer.0.intermediate.dense.weight\", \"model.encoder.layer.0.output.dense.weight\", \"model.encoder.layer.1.attention.self.query.weight\", \"model.encoder.layer.1.attention.self.key.weight\", \"model.encoder.layer.1.attention.self.value.weight\", \"model.encoder.layer.1.attention.output.dense.weight\", \"model.encoder.layer.1.intermediate.dense.weight\", \"model.encoder.layer.1.output.dense.weight\", \"model.encoder.layer.2.attention.self.query.weight\", \"model.encoder.layer.2.attention.self.key.weight\", \"model.encoder.layer.2.attention.self.value.weight\", \"model.encoder.layer.2.attention.output.dense.weight\", \"model.encoder.layer.2.intermediate.dense.weight\", \"model.encoder.layer.2.output.dense.weight\", \"model.encoder.layer.3.attention.self.query.weight\", \"model.encoder.layer.3.attention.self.key.weight\", \"model.encoder.layer.3.attention.self.value.weight\", \"model.encoder.layer.3.attention.output.dense.weight\", \"model.encoder.layer.3.intermediate.dense.weight\", \"model.encoder.layer.3.output.dense.weight\", \"model.encoder.layer.4.attention.self.query.weight\", \"model.encoder.layer.4.attention.self.key.weight\", \"model.encoder.layer.4.attention.self.value.weight\", \"model.encoder.layer.4.attention.output.dense.weight\", \"model.encoder.layer.4.intermediate.dense.weight\", \"model.encoder.layer.4.output.dense.weight\", \"model.encoder.layer.5.attention.self.query.weight\", \"model.encoder.layer.5.attention.self.key.weight\", \"model.encoder.layer.5.attention.self.value.weight\", \"model.encoder.layer.5.attention.output.dense.weight\", \"model.encoder.layer.5.intermediate.dense.weight\", \"model.encoder.layer.5.output.dense.weight\", \"model.encoder.layer.6.attention.self.query.weight\", \"model.encoder.layer.6.attention.self.key.weight\", \"model.encoder.layer.6.attention.self.value.weight\", \"model.encoder.layer.6.attention.output.dense.weight\", \"model.encoder.layer.6.intermediate.dense.weight\", \"model.encoder.layer.6.output.dense.weight\", \"model.encoder.layer.7.attention.self.query.weight\", \"model.encoder.layer.7.attention.self.key.weight\", \"model.encoder.layer.7.attention.self.value.weight\", \"model.encoder.layer.7.attention.output.dense.weight\", \"model.encoder.layer.7.intermediate.dense.weight\", \"model.encoder.layer.7.output.dense.weight\", \"model.encoder.layer.8.attention.self.query.weight\", \"model.encoder.layer.8.attention.self.key.weight\", \"model.encoder.layer.8.attention.self.value.weight\", \"model.encoder.layer.8.attention.output.dense.weight\", \"model.encoder.layer.8.intermediate.dense.weight\", \"model.encoder.layer.8.output.dense.weight\", \"model.encoder.layer.9.attention.self.query.weight\", \"model.encoder.layer.9.attention.self.key.weight\", \"model.encoder.layer.9.attention.self.value.weight\", \"model.encoder.layer.9.attention.output.dense.weight\", \"model.encoder.layer.9.intermediate.dense.weight\", \"model.encoder.layer.9.output.dense.weight\", \"model.encoder.layer.10.attention.self.query.weight\", \"model.encoder.layer.10.attention.self.key.weight\", \"model.encoder.layer.10.attention.self.value.weight\", \"model.encoder.layer.10.attention.output.dense.weight\", \"model.encoder.layer.10.intermediate.dense.weight\", \"model.encoder.layer.10.output.dense.weight\", \"model.encoder.layer.11.attention.self.query.weight\", \"model.encoder.layer.11.attention.self.key.weight\", \"model.encoder.layer.11.attention.self.value.weight\", \"model.encoder.layer.11.attention.output.dense.weight\", \"model.encoder.layer.11.intermediate.dense.weight\", \"model.encoder.layer.11.output.dense.weight\", \"ner_classifier.weight\". \n\tUnexpected key(s) in state_dict: \"onnx::MatMul_1288\", \"onnx::MatMul_1289\", \"onnx::MatMul_1295\", \"onnx::MatMul_1310\", \"onnx::MatMul_1311\", \"onnx::MatMul_1312\", \"onnx::MatMul_1313\", \"onnx::MatMul_1314\", \"onnx::MatMul_1320\", \"onnx::MatMul_1335\", \"onnx::MatMul_1336\", \"onnx::MatMul_1337\", \"onnx::MatMul_1338\", \"onnx::MatMul_1339\", \"onnx::MatMul_1345\", \"onnx::MatMul_1360\", \"onnx::MatMul_1361\", \"onnx::MatMul_1362\", \"onnx::MatMul_1363\", \"onnx::MatMul_1364\", \"onnx::MatMul_1370\", \"onnx::MatMul_1385\", \"onnx::MatMul_1386\", \"onnx::MatMul_1387\", \"onnx::MatMul_1388\", \"onnx::MatMul_1389\", \"onnx::MatMul_1395\", \"onnx::MatMul_1410\", \"onnx::MatMul_1411\", \"onnx::MatMul_1412\", \"onnx::MatMul_1413\", \"onnx::MatMul_1414\", \"onnx::MatMul_1420\", \"onnx::MatMul_1435\", \"onnx::MatMul_1436\", \"onnx::MatMul_1437\", \"onnx::MatMul_1438\", \"onnx::MatMul_1439\", \"onnx::MatMul_1445\", \"onnx::MatMul_1460\", \"onnx::MatMul_1461\", \"onnx::MatMul_1462\", \"onnx::MatMul_1463\", \"onnx::MatMul_1464\", \"onnx::MatMul_1470\", \"onnx::MatMul_1485\", \"onnx::MatMul_1486\", \"onnx::MatMul_1487\", \"onnx::MatMul_1488\", \"onnx::MatMul_1489\", \"onnx::MatMul_1495\", \"onnx::MatMul_1510\", \"onnx::MatMul_1511\", \"onnx::MatMul_1512\", \"onnx::MatMul_1513\", \"onnx::MatMul_1514\", \"onnx::MatMul_1520\", \"onnx::MatMul_1535\", \"onnx::MatMul_1536\", \"onnx::MatMul_1537\", \"onnx::MatMul_1538\", \"onnx::MatMul_1539\", \"onnx::MatMul_1545\", \"onnx::MatMul_1560\", \"onnx::MatMul_1561\", \"onnx::MatMul_1562\", \"onnx::MatMul_1563\", \"onnx::MatMul_1564\", \"onnx::MatMul_1570\", \"onnx::MatMul_1585\", \"onnx::MatMul_1586\", \"onnx::MatMul_1587\", \"onnx::MatMul_1588\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-decb596209c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2153\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MultiTaskBertModel:\n\tMissing key(s) in state_dict: \"model.encoder.layer.0.attention.self.query.weight\", \"model.encoder.layer.0.attention.self.key.weight\", \"model.encoder.layer.0.attention.self.value.weight\", \"model.encoder.layer.0.attention.output.dense.weight\", \"model.encoder.layer.0.intermediate.dense.weight\", \"model.encoder.layer.0.output.dense.weight\", \"model.encoder.layer.1.attention.self.query.weight\", \"model.encoder.layer.1.attention.self.key.weight\", \"model.encoder.layer.1.attention.self.value.weight\", \"model.encoder.layer.1.attention.output.dense.weight\", \"model.encoder.layer.1.intermediate.dense.weight\", \"model.encoder.layer.1.output.dense.weight\", \"model.encoder.layer.2.attention.self.query.weight\", \"model.encoder.layer.2.attention.self.key.weight\", \"model.encoder.layer.2.attention.self.value.weight\", \"model.encoder.layer.2.attention.output.dense.weight\", \"model.encoder.layer.2.intermediate.dense.weight\", \"model.encoder.layer.2.output.dense.weight\", \"model.encoder.layer.3.attention.self.query.weight\", \"model.encoder.layer.3.attention.self.key.weight\", \"model.encoder.layer.3.attention.self.value.weight\", \"model.encoder.layer.3.attention.output.dense.weight\", \"model.encoder.layer.3.intermediate.dense.weight\", \"model.encoder.layer.3.output.dense.weight\", \"model.encoder.layer.4.attention.self.query.weight\", \"model.encoder.layer.4.attention.self.key.weight\", \"model.encoder.layer.4.attention.self.value.weight\", \"model.encoder.layer.4.attention.output.dense.weight\", \"model.encoder.layer.4...\n\tUnexpected key(s) in state_dict: \"onnx::MatMul_1288\", \"onnx::MatMul_1289\", \"onnx::MatMul_1295\", \"onnx::MatMul_1310\", \"onnx::MatMul_1311\", \"onnx::MatMul_1312\", \"onnx::MatMul_1313\", \"onnx::MatMul_1314\", \"onnx::MatMul_1320\", \"onnx::MatMul_1335\", \"onnx::MatMul_1336\", \"onnx::MatMul_1337\", \"onnx::MatMul_1338\", \"onnx::MatMul_1339\", \"onnx::MatMul_1345\", \"onnx::MatMul_1360\", \"onnx::MatMul_1361\", \"onnx::MatMul_1362\", \"onnx::MatMul_1363\", \"onnx::MatMul_1364\", \"onnx::MatMul_1370\", \"onnx::MatMul_1385\", \"onnx::MatMul_1386\", \"onnx::MatMul_1387\", \"onnx::MatMul_1388\", \"onnx::MatMul_1389\", \"onnx::MatMul_1395\", \"onnx::MatMul_1410\", \"onnx::MatMul_1411\", \"onnx::MatMul_1412\", \"onnx::MatMul_1413\", \"onnx::MatMul_1414\", \"onnx::MatMul_1420\", \"onnx::MatMul_1435\", \"onnx::MatMul_1436\", \"onnx::MatMul_1437\", \"onnx::MatMul_1438\", \"onnx::MatMul_1439\", \"onnx::MatMul_1445\", \"onnx::MatMul_1460\", \"onnx::MatMul_1461\", \"onnx::MatMul_1462\", \"onnx::MatMul_1463\", \"onnx::MatMul_1464\", \"onnx::MatMul_1470\", \"onnx::MatMul_1485\", \"onnx::MatMul_1486\", \"onnx::MatMul_1487\", \"onnx::MatMul_1488\", \"onnx::MatMul_1489\", \"onnx::MatMul_1495\", \"onnx::MatMul_1510\", \"onnx::MatMul_1511\", \"onnx::MatMul_1512\", \"onnx::MatMul_1513\", \"onnx::MatMul_1514\", \"onnx::MatMul_1520\", \"onnx::MatMul_1535\", \"onnx::MatMul_1536\", \"onnx::MatMul_1537\", \"onnx::MatMul_1538\", \"onnx::MatMul_1539\", \"onnx::MatMul_1545\", \"onnx::MatMul_1560\", \"onnx::MatMul_1561\", \"onnx::MatMul_1562\", \"onnx::MatMul_1563\", \"onnx::MatMul_1564\", \"onnx::MatMul_1570\", \"onnx::MatMul_..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scripted_model = model.to_torchscript(file_path=artifact_dir)"
      ],
      "metadata": {
        "id": "vqbXQrL660uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Save the TorchScript model to a .pt file\n",
        "torch.jit.save(model, \"model.pt\")\n",
        "\n",
        "# Step 2: Log the .pt file as an artifact\n",
        "run = wandb.init(project=\"prince\", job_type=\"model_upload\")\n",
        "artifact = wandb.Artifact(\"model\", type=\"model\")\n",
        "artifact.add_file(\"model.pt\")\n",
        "run.log_artifact(artifact)\n",
        "\n",
        "# Step 3: Finish the run\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "5C1ZNcvb8A7e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}