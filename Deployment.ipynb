{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f17e362029b9439faf39049dac526bd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_718c4e8133d2448ba4bf60a489a1f16c",
              "IPY_MODEL_482917232d984c839ae59bd694fec372",
              "IPY_MODEL_f24b7285edba4bd18fd6b57826ddbca7"
            ],
            "layout": "IPY_MODEL_560af5d8d0b94da69a83133d5415a6e0"
          }
        },
        "718c4e8133d2448ba4bf60a489a1f16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d304bb64d11e4c869d7991615d81e220",
            "placeholder": "​",
            "style": "IPY_MODEL_43a0617056dd414eb75c82e5bb07d7ea",
            "value": "config.json: 100%"
          }
        },
        "482917232d984c839ae59bd694fec372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b2be7372fdc49fdb40bda6b2e32c282",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e96d75467164671a6c97c408f1ec1d9",
            "value": 570
          }
        },
        "f24b7285edba4bd18fd6b57826ddbca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a3b8b3288a54af4848c2d6249153d95",
            "placeholder": "​",
            "style": "IPY_MODEL_30b3b5fba7ca49b39e30ad293a46bec7",
            "value": " 570/570 [00:00&lt;00:00, 14.2kB/s]"
          }
        },
        "560af5d8d0b94da69a83133d5415a6e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d304bb64d11e4c869d7991615d81e220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a0617056dd414eb75c82e5bb07d7ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b2be7372fdc49fdb40bda6b2e32c282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e96d75467164671a6c97c408f1ec1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a3b8b3288a54af4848c2d6249153d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b3b5fba7ca49b39e30ad293a46bec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8Yda_U1XKPS",
        "outputId": "c8004d42-1f55-4267-88ee-9963cdb8fd5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.2.0.post0-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.9/800.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.40.4-py2.py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.9/257.9 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.9.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.20.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, onnx, lightning-utilities, docker-pycreds, gitdb, torchmetrics, GitPython, wandb, pytorch-lightning\n",
            "Successfully installed GitPython-3.1.41 docker-pycreds-0.4.0 gitdb-4.0.11 lightning-utilities-0.10.1 onnx-1.15.0 pytorch-lightning-2.2.0.post0 sentry-sdk-1.40.4 setproctitle-1.3.3 smmap-5.0.1 torchmetrics-1.3.1 wandb-0.16.3\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb pytorch-lightning transformers[sentencepiece] onnx onnx-torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from transformers import BertModel, BertConfig, BertTokenizerFast\n",
        "from torchmetrics import Metric\n",
        "import os\n",
        "import onnx\n",
        "import onnx.numpy_helper as numpy_helper\n",
        "import json\n",
        "import numpy as np\n",
        "import onnxruntime\n",
        "from onnx2pytorch import ConvertModel"
      ],
      "metadata": {
        "id": "Ke2MfmPrbPCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init()\n",
        "artifact = run.use_artifact('prince_/lit-wandb/model.ckpt:v39', type='model')\n",
        "artifact_dir = artifact.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "Wxlo7Ub-ZrR4",
        "outputId": "656961cd-78c2-4e30-b96a-3cf0a05e0726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240211_064644-2z1k1a26</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/prince_/uncategorized/runs/2z1k1a26' target=\"_blank\">fortuitous-rocket-10</a></strong> to <a href='https://wandb.ai/prince_/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/prince_/uncategorized' target=\"_blank\">https://wandb.ai/prince_/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/prince_/uncategorized/runs/2z1k1a26' target=\"_blank\">https://wandb.ai/prince_/uncategorized/runs/2z1k1a26</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model.ckpt:v39, 417.81MB. 1 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 0:0:9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.use_artifact??"
      ],
      "metadata": {
        "id": "iMs2yA6UqxFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the documentation on hot to save the model in torch"
      ],
      "metadata": {
        "id": "UX-tS1UUrT3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pl.LightningModule.to_torchscript??"
      ],
      "metadata": {
        "id": "MjKhhlB_bQuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/model/B_data.json\"\n",
        "with open(path, 'r') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "path = \"/content/drive/MyDrive/model/training_set.json\"\n",
        "with open(path, 'r') as f:\n",
        "    test_dataset = json.load(f)\n",
        "\n",
        "text, intent, ner = [], [], []\n",
        "for i in dataset:\n",
        "    text.append(i['text'])\n",
        "    intent.append(i['intent'])\n",
        "    ner.append(i['entities'].split())\n",
        "\n",
        "test_text, test_intent, test_ner = [], [], []\n",
        "for i in test_dataset:\n",
        "    test_text.append(i['text'])\n",
        "    test_intent.append(i['intent'])\n",
        "    test_ner.append(i['entities'].split())\n",
        "\n",
        "unique_intents = set(intent)\n",
        "num_intent_labels = len(unique_intents)\n",
        "\n",
        "one_dimensional_ner = [tag for subset in ner for tag in subset ]\n",
        "unique_ner = set(one_dimensional_ner)\n",
        "num_ner_labels = len(unique_ner)\n",
        "\n"
      ],
      "metadata": {
        "id": "lkMYyRezWSWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_ner_labels, num_intent_labels = 9, 5"
      ],
      "metadata": {
        "id": "PV-_K10i6Ksv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyAccuracy(Metric):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.add_state('total', default=torch.tensor(0), dist_reduce_fx='sum')\n",
        "        self.add_state('correct', default=torch.tensor(0), dist_reduce_fx='sum')\n",
        "\n",
        "    def update(self, logits, labels, num_labels):\n",
        "\n",
        "        flattened_targets = labels.view(-1) # shape (batch_size, sequence_len)\n",
        "        active_logits = logits.view(-1, num_labels) # shape (batch_size * sequence_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * sequence_len)\n",
        "\n",
        "        # compute accuracy only at active labels\n",
        "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, sequnce_len)\n",
        "        ac_labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        self.correct += torch.sum(ac_labels == predictions)\n",
        "        self.total += torch.numel(ac_labels)\n",
        "\n",
        "    def compute(self):\n",
        "        return self.correct.float() / self.total.float()"
      ],
      "metadata": {
        "id": "5dVTD3Ae3J1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskBertModel(pl.LightningModule):\n",
        "\n",
        "    \"\"\"\n",
        "    Multi-task Bert model for Named Entity Recognition (NER) and Intent Classification\n",
        "\n",
        "    Args:\n",
        "        config (BertConfig): Bert model configuration.\n",
        "        num_ner_labels (int): The number of labels for NER task.\n",
        "        num_intent_labels (int): The number of labels for Intent Classification task.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, num_ner_labels, num_intent_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_ner_labels = num_ner_labels\n",
        "        self.num_intent_labels = num_intent_labels\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        self.model = BertModel(config=config)\n",
        "\n",
        "        self.ner_classifier = torch.nn.Linear(config.hidden_size, self.num_ner_labels)\n",
        "        self.intent_classifier = torch.nn.Linear(config.hidden_size, self.num_intent_labels)\n",
        "\n",
        "        # log hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.accuracy = MyAccuracy()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None):\n",
        "\n",
        "        \"\"\"\n",
        "        Perform a forward pass through Multi-task Bert model.\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): Input token IDs.\n",
        "            attention_mask (torch.Tensor): Attention mask for input tokens.\n",
        "            ner_labels (torch.Tensor): Labels for NER task.\n",
        "            intent_labels (torch.Tensor): Labels for Intent Classification task.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor,torch.Tensor,torch.Tensor,torch.Tensor]: NER loss, NER logits, Intent loss, Intent logits.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If ner_labels or intent_labels were not provided.\n",
        "        \"\"\"\n",
        "\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        ner_logits = self.ner_classifier(sequence_output)\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        intent_logits = self.intent_classifier(pooled_output)\n",
        "\n",
        "        return ner_logits, intent_logits\n",
        "\n",
        "    def training_step(self: pl.LightningModule, batch, batch_idx: int):\n",
        "        loss, ner_logits, intent_logits, ner_labels, intent_labels = self._common_step(batch, batch_idx)\n",
        "        accuracy_ner = self.accuracy(ner_logits, ner_labels, num_ner_labels)\n",
        "        accuracy_intent = self.accuracy(intent_logits, intent_labels, num_intent_labels)\n",
        "        self.log_dict({'training_loss': loss, 'ner_accuracy': accuracy_ner, 'intent_accuracy': accuracy_intent},\n",
        "                      on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_start(self):\n",
        "        self.validation_step_outputs_ner = []\n",
        "        self.validation_step_outputs_intent = []\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, ner_logits, intent_logits, ner_labels, intent_labels = self._common_step(batch, batch_idx)\n",
        "        # self.log('val_loss', loss)\n",
        "        accuracy_ner = self.accuracy(ner_logits, ner_labels, num_ner_labels)\n",
        "        accuracy_intent = self.accuracy(intent_logits, intent_labels, num_intent_labels)\n",
        "        self.log_dict({'validation_loss': loss, 'val_ner_accuracy': accuracy_ner, 'val_intent_accuracy': accuracy_intent},\n",
        "                      on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        self.validation_step_outputs_ner.append(ner_logits)\n",
        "        self.validation_step_outputs_intent.append(intent_logits)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        validation_step_outputs_ner = self.validation_step_outputs_ner\n",
        "        validation_step_outputs_intent = self.validation_step_outputs_intent\n",
        "\n",
        "        dummy_input = torch.zeros((1, 128), device=self.device, dtype=torch.long)\n",
        "        model_filename = f\"model_{str(self.global_step).zfill(5)}.onnx\"\n",
        "        torch.onnx.export(self, dummy_input, model_filename)\n",
        "        artifact = wandb.Artifact(name=\"model.ckpt\", type=\"model\")\n",
        "        artifact.add_file(model_filename)\n",
        "        self.logger.experiment.log_artifact(artifact)\n",
        "\n",
        "        flattened_logits_ner = torch.flatten(torch.cat(validation_step_outputs_ner))\n",
        "        flattened_logits_intent = torch.flatten(torch.cat(validation_step_outputs_intent))\n",
        "        self.logger.experiment.log(\n",
        "            {\"valid/ner_logits\": wandb.Histogram(flattened_logits_ner.to('cpu')),\n",
        "             \"valid/intent_logits\": wandb.Histogram(flattened_logits_intent.to('cpu')),\n",
        "             \"global_step\": self.global_step}\n",
        "        )\n",
        "\n",
        "    def _common_step(self, batch, batch_idx):\n",
        "        ids = batch['input_ids']\n",
        "        mask = batch['attention_mask']\n",
        "        ner_labels = batch['ner_labels']\n",
        "        intent_labels = batch['intent_labels']\n",
        "\n",
        "        ner_logits, intent_logits = self.forward(ids, mask)\n",
        "\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        ner_loss = criterion(ner_logits.view(-1, self.num_ner_labels), ner_labels.view(-1))\n",
        "        intent_loss = criterion(intent_logits.view(-1, self.num_intent_labels), intent_labels.view(-1))\n",
        "\n",
        "        loss = ner_loss + intent_loss\n",
        "        return loss, ner_logits, intent_logits, ner_labels, intent_labels\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-5)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "BTtfIyOm0EfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BertConfig.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "maX6y2v_3rOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "f17e362029b9439faf39049dac526bd5",
            "718c4e8133d2448ba4bf60a489a1f16c",
            "482917232d984c839ae59bd694fec372",
            "f24b7285edba4bd18fd6b57826ddbca7",
            "560af5d8d0b94da69a83133d5415a6e0",
            "d304bb64d11e4c869d7991615d81e220",
            "43a0617056dd414eb75c82e5bb07d7ea",
            "9b2be7372fdc49fdb40bda6b2e32c282",
            "8e96d75467164671a6c97c408f1ec1d9",
            "3a3b8b3288a54af4848c2d6249153d95",
            "30b3b5fba7ca49b39e30ad293a46bec7"
          ]
        },
        "outputId": "5327abac-468a-445c-aba7-3ca54ebbf038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f17e362029b9439faf39049dac526bd5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiTaskBertModel(config, num_ner_labels, num_intent_labels)"
      ],
      "metadata": {
        "id": "6DeHcXps6WS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "gtJcQcc-tq4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7i95W47ftrEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "auAZDSPItrap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WAIT"
      ],
      "metadata": {
        "id": "IG6Ygnm6tsAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = 0\n",
        "for name, param in model.named_parameters():\n",
        "    total_params += param.numel()\n",
        "\n",
        "print(\"Total number of parameters in the model:\", total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLmvVnsx8heS",
        "outputId": "f712fce8-765e-4a19-be8f-ed01b661fdd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 109493006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the model into pth format"
      ],
      "metadata": {
        "id": "UdIQtVoC6aCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model = onnx.load(os.path.join(artifact_dir, \"model_00105.onnx\"))"
      ],
      "metadata": {
        "id": "aHICmJzYXsID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the ONNX model to a PyTorch model\n",
        "torch_model = torch.onnx.load(onnx_model)\n",
        "\n",
        "# Save the PyTorch model weights\n",
        "torch.save(torch_model.state_dict(), \"pytorch_model.bin\")"
      ],
      "metadata": {
        "id": "XV8C5uHauetA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XDIF3acf6LCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving config in json format"
      ],
      "metadata": {
        "id": "cjtqZNnL6xDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_dict = config.to_dict()\n",
        "\n",
        "with open('config.json', \"w\") as json_file:\n",
        "    json.dump(config_dict, json_file, indent=4)"
      ],
      "metadata": {
        "id": "MOVM-vIP60n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the tokenizer"
      ],
      "metadata": {
        "id": "juEbyI2g7RAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_tokenizer_config(tokenizer, filename):\n",
        "    tokenizer_config = tokenizer.save_pretrained(filename)\n",
        "    # Save the tokenizer config to a JSON file\n",
        "    with open(filename + '/tokenizer_config.json', 'w') as config_file:\n",
        "        json.dump(tokenizer_config, config_file)\n",
        "\n",
        "# Save label dictionaries\n",
        "def save_label_dict(label_dict, filename):\n",
        "    with open(filename, 'w') as label_file:\n",
        "        json.dump(label_dict, label_file)"
      ],
      "metadata": {
        "id": "Vv-ja4Oj7krF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_to_ids_ner = {\n",
        "    'O': 0,\n",
        "    'B-DATE': 1,\n",
        "    'I-DATE': 2,\n",
        "    'B-TIME': 3,\n",
        "    'I-TIME': 4,\n",
        "    'B-TASK': 5,\n",
        "    'I-TASK': 6,\n",
        "    'B-DUR': 7,\n",
        "    'I-DUR': 8\n",
        "    }"
      ],
      "metadata": {
        "id": "Q_nKnysCQ_NE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_to_ids_intent = {\n",
        "    \"'Schedule Appointment'\": 0,\n",
        "    \"'Schedule Meeting'\": 1,\n",
        "    \"'Set Alarm'\": 2,\n",
        "    \"'Set Reminder'\": 3,\n",
        "    \"'Set Timer'\": 4\n",
        "}"
      ],
      "metadata": {
        "id": "gwAcZJpqRByz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_dir = \"tokenizer\"\n",
        "save_tokenizer_config(tokenizer, tokenizer_dir)\n",
        "\n",
        "save_label_dict(labels_to_ids_ner, \"ner_labels.json\")\n",
        "save_label_dict(labels_to_ids_intent, \"intent_labels.json\")"
      ],
      "metadata": {
        "id": "9VxsiZ92Ou75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "____\n"
      ],
      "metadata": {
        "id": "_ONhCyRk7lDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = {}\n",
        "\n",
        "for initializer in onnx_model.graph.initializer:\n",
        "    # Convert the initializer's data to a PyTorch tensor\n",
        "    tensor = numpy_helper.to_array(initializer)\n",
        "\n",
        "    # Use the initializer's name as the key in the state_dict\n",
        "    state_dict[initializer.name] = torch.tensor(tensor)"
      ],
      "metadata": {
        "id": "V-YHlTRjEPlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in state_dict.values())\n",
        "total_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKUvBeom8lQJ",
        "outputId": "5b407e6f-2541-42e2-a1b7-b63e4d965116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109493006"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict"
      ],
      "metadata": {
        "id": "ZpAjngKLXRIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "gpgyy5Xv_OB0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49ea6093-4013-4768-a0c0-03888430cdf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for MultiTaskBertModel:\n\tMissing key(s) in state_dict: \"model.encoder.layer.0.attention.self.query.weight\", \"model.encoder.layer.0.attention.self.key.weight\", \"model.encoder.layer.0.attention.self.value.weight\", \"model.encoder.layer.0.attention.output.dense.weight\", \"model.encoder.layer.0.intermediate.dense.weight\", \"model.encoder.layer.0.output.dense.weight\", \"model.encoder.layer.1.attention.self.query.weight\", \"model.encoder.layer.1.attention.self.key.weight\", \"model.encoder.layer.1.attention.self.value.weight\", \"model.encoder.layer.1.attention.output.dense.weight\", \"model.encoder.layer.1.intermediate.dense.weight\", \"model.encoder.layer.1.output.dense.weight\", \"model.encoder.layer.2.attention.self.query.weight\", \"model.encoder.layer.2.attention.self.key.weight\", \"model.encoder.layer.2.attention.self.value.weight\", \"model.encoder.layer.2.attention.output.dense.weight\", \"model.encoder.layer.2.intermediate.dense.weight\", \"model.encoder.layer.2.output.dense.weight\", \"model.encoder.layer.3.attention.self.query.weight\", \"model.encoder.layer.3.attention.self.key.weight\", \"model.encoder.layer.3.attention.self.value.weight\", \"model.encoder.layer.3.attention.output.dense.weight\", \"model.encoder.layer.3.intermediate.dense.weight\", \"model.encoder.layer.3.output.dense.weight\", \"model.encoder.layer.4.attention.self.query.weight\", \"model.encoder.layer.4.attention.self.key.weight\", \"model.encoder.layer.4.attention.self.value.weight\", \"model.encoder.layer.4.attention.output.dense.weight\", \"model.encoder.layer.4.intermediate.dense.weight\", \"model.encoder.layer.4.output.dense.weight\", \"model.encoder.layer.5.attention.self.query.weight\", \"model.encoder.layer.5.attention.self.key.weight\", \"model.encoder.layer.5.attention.self.value.weight\", \"model.encoder.layer.5.attention.output.dense.weight\", \"model.encoder.layer.5.intermediate.dense.weight\", \"model.encoder.layer.5.output.dense.weight\", \"model.encoder.layer.6.attention.self.query.weight\", \"model.encoder.layer.6.attention.self.key.weight\", \"model.encoder.layer.6.attention.self.value.weight\", \"model.encoder.layer.6.attention.output.dense.weight\", \"model.encoder.layer.6.intermediate.dense.weight\", \"model.encoder.layer.6.output.dense.weight\", \"model.encoder.layer.7.attention.self.query.weight\", \"model.encoder.layer.7.attention.self.key.weight\", \"model.encoder.layer.7.attention.self.value.weight\", \"model.encoder.layer.7.attention.output.dense.weight\", \"model.encoder.layer.7.intermediate.dense.weight\", \"model.encoder.layer.7.output.dense.weight\", \"model.encoder.layer.8.attention.self.query.weight\", \"model.encoder.layer.8.attention.self.key.weight\", \"model.encoder.layer.8.attention.self.value.weight\", \"model.encoder.layer.8.attention.output.dense.weight\", \"model.encoder.layer.8.intermediate.dense.weight\", \"model.encoder.layer.8.output.dense.weight\", \"model.encoder.layer.9.attention.self.query.weight\", \"model.encoder.layer.9.attention.self.key.weight\", \"model.encoder.layer.9.attention.self.value.weight\", \"model.encoder.layer.9.attention.output.dense.weight\", \"model.encoder.layer.9.intermediate.dense.weight\", \"model.encoder.layer.9.output.dense.weight\", \"model.encoder.layer.10.attention.self.query.weight\", \"model.encoder.layer.10.attention.self.key.weight\", \"model.encoder.layer.10.attention.self.value.weight\", \"model.encoder.layer.10.attention.output.dense.weight\", \"model.encoder.layer.10.intermediate.dense.weight\", \"model.encoder.layer.10.output.dense.weight\", \"model.encoder.layer.11.attention.self.query.weight\", \"model.encoder.layer.11.attention.self.key.weight\", \"model.encoder.layer.11.attention.self.value.weight\", \"model.encoder.layer.11.attention.output.dense.weight\", \"model.encoder.layer.11.intermediate.dense.weight\", \"model.encoder.layer.11.output.dense.weight\", \"ner_classifier.weight\". \n\tUnexpected key(s) in state_dict: \"onnx::MatMul_1288\", \"onnx::MatMul_1289\", \"onnx::MatMul_1295\", \"onnx::MatMul_1310\", \"onnx::MatMul_1311\", \"onnx::MatMul_1312\", \"onnx::MatMul_1313\", \"onnx::MatMul_1314\", \"onnx::MatMul_1320\", \"onnx::MatMul_1335\", \"onnx::MatMul_1336\", \"onnx::MatMul_1337\", \"onnx::MatMul_1338\", \"onnx::MatMul_1339\", \"onnx::MatMul_1345\", \"onnx::MatMul_1360\", \"onnx::MatMul_1361\", \"onnx::MatMul_1362\", \"onnx::MatMul_1363\", \"onnx::MatMul_1364\", \"onnx::MatMul_1370\", \"onnx::MatMul_1385\", \"onnx::MatMul_1386\", \"onnx::MatMul_1387\", \"onnx::MatMul_1388\", \"onnx::MatMul_1389\", \"onnx::MatMul_1395\", \"onnx::MatMul_1410\", \"onnx::MatMul_1411\", \"onnx::MatMul_1412\", \"onnx::MatMul_1413\", \"onnx::MatMul_1414\", \"onnx::MatMul_1420\", \"onnx::MatMul_1435\", \"onnx::MatMul_1436\", \"onnx::MatMul_1437\", \"onnx::MatMul_1438\", \"onnx::MatMul_1439\", \"onnx::MatMul_1445\", \"onnx::MatMul_1460\", \"onnx::MatMul_1461\", \"onnx::MatMul_1462\", \"onnx::MatMul_1463\", \"onnx::MatMul_1464\", \"onnx::MatMul_1470\", \"onnx::MatMul_1485\", \"onnx::MatMul_1486\", \"onnx::MatMul_1487\", \"onnx::MatMul_1488\", \"onnx::MatMul_1489\", \"onnx::MatMul_1495\", \"onnx::MatMul_1510\", \"onnx::MatMul_1511\", \"onnx::MatMul_1512\", \"onnx::MatMul_1513\", \"onnx::MatMul_1514\", \"onnx::MatMul_1520\", \"onnx::MatMul_1535\", \"onnx::MatMul_1536\", \"onnx::MatMul_1537\", \"onnx::MatMul_1538\", \"onnx::MatMul_1539\", \"onnx::MatMul_1545\", \"onnx::MatMul_1560\", \"onnx::MatMul_1561\", \"onnx::MatMul_1562\", \"onnx::MatMul_1563\", \"onnx::MatMul_1564\", \"onnx::MatMul_1570\", \"onnx::MatMul_1585\", \"onnx::MatMul_1586\", \"onnx::MatMul_1587\", \"onnx::MatMul_1588\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-decb596209c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2153\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MultiTaskBertModel:\n\tMissing key(s) in state_dict: \"model.encoder.layer.0.attention.self.query.weight\", \"model.encoder.layer.0.attention.self.key.weight\", \"model.encoder.layer.0.attention.self.value.weight\", \"model.encoder.layer.0.attention.output.dense.weight\", \"model.encoder.layer.0.intermediate.dense.weight\", \"model.encoder.layer.0.output.dense.weight\", \"model.encoder.layer.1.attention.self.query.weight\", \"model.encoder.layer.1.attention.self.key.weight\", \"model.encoder.layer.1.attention.self.value.weight\", \"model.encoder.layer.1.attention.output.dense.weight\", \"model.encoder.layer.1.intermediate.dense.weight\", \"model.encoder.layer.1.output.dense.weight\", \"model.encoder.layer.2.attention.self.query.weight\", \"model.encoder.layer.2.attention.self.key.weight\", \"model.encoder.layer.2.attention.self.value.weight\", \"model.encoder.layer.2.attention.output.dense.weight\", \"model.encoder.layer.2.intermediate.dense.weight\", \"model.encoder.layer.2.output.dense.weight\", \"model.encoder.layer.3.attention.self.query.weight\", \"model.encoder.layer.3.attention.self.key.weight\", \"model.encoder.layer.3.attention.self.value.weight\", \"model.encoder.layer.3.attention.output.dense.weight\", \"model.encoder.layer.3.intermediate.dense.weight\", \"model.encoder.layer.3.output.dense.weight\", \"model.encoder.layer.4.attention.self.query.weight\", \"model.encoder.layer.4.attention.self.key.weight\", \"model.encoder.layer.4.attention.self.value.weight\", \"model.encoder.layer.4.attention.output.dense.weight\", \"model.encoder.layer.4...\n\tUnexpected key(s) in state_dict: \"onnx::MatMul_1288\", \"onnx::MatMul_1289\", \"onnx::MatMul_1295\", \"onnx::MatMul_1310\", \"onnx::MatMul_1311\", \"onnx::MatMul_1312\", \"onnx::MatMul_1313\", \"onnx::MatMul_1314\", \"onnx::MatMul_1320\", \"onnx::MatMul_1335\", \"onnx::MatMul_1336\", \"onnx::MatMul_1337\", \"onnx::MatMul_1338\", \"onnx::MatMul_1339\", \"onnx::MatMul_1345\", \"onnx::MatMul_1360\", \"onnx::MatMul_1361\", \"onnx::MatMul_1362\", \"onnx::MatMul_1363\", \"onnx::MatMul_1364\", \"onnx::MatMul_1370\", \"onnx::MatMul_1385\", \"onnx::MatMul_1386\", \"onnx::MatMul_1387\", \"onnx::MatMul_1388\", \"onnx::MatMul_1389\", \"onnx::MatMul_1395\", \"onnx::MatMul_1410\", \"onnx::MatMul_1411\", \"onnx::MatMul_1412\", \"onnx::MatMul_1413\", \"onnx::MatMul_1414\", \"onnx::MatMul_1420\", \"onnx::MatMul_1435\", \"onnx::MatMul_1436\", \"onnx::MatMul_1437\", \"onnx::MatMul_1438\", \"onnx::MatMul_1439\", \"onnx::MatMul_1445\", \"onnx::MatMul_1460\", \"onnx::MatMul_1461\", \"onnx::MatMul_1462\", \"onnx::MatMul_1463\", \"onnx::MatMul_1464\", \"onnx::MatMul_1470\", \"onnx::MatMul_1485\", \"onnx::MatMul_1486\", \"onnx::MatMul_1487\", \"onnx::MatMul_1488\", \"onnx::MatMul_1489\", \"onnx::MatMul_1495\", \"onnx::MatMul_1510\", \"onnx::MatMul_1511\", \"onnx::MatMul_1512\", \"onnx::MatMul_1513\", \"onnx::MatMul_1514\", \"onnx::MatMul_1520\", \"onnx::MatMul_1535\", \"onnx::MatMul_1536\", \"onnx::MatMul_1537\", \"onnx::MatMul_1538\", \"onnx::MatMul_1539\", \"onnx::MatMul_1545\", \"onnx::MatMul_1560\", \"onnx::MatMul_1561\", \"onnx::MatMul_1562\", \"onnx::MatMul_1563\", \"onnx::MatMul_1564\", \"onnx::MatMul_1570\", \"onnx::MatMul_..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scripted_model = model.to_torchscript(file_path=artifact_dir)"
      ],
      "metadata": {
        "id": "vqbXQrL660uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Save the TorchScript model to a .pt file\n",
        "torch.jit.save(model, \"model.pt\")\n",
        "\n",
        "# Step 2: Log the .pt file as an artifact\n",
        "run = wandb.init(project=\"prince\", job_type=\"model_upload\")\n",
        "artifact = wandb.Artifact(\"model\", type=\"model\")\n",
        "artifact.add_file(\"model.pt\")\n",
        "run.log_artifact(artifact)\n",
        "\n",
        "# Step 3: Finish the run\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "5C1ZNcvb8A7e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}